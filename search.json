[{
    "title": "Android",
    "url": "https://hmaier-dev.github.io/wiki/android/",
    "content": "TLD;DR Enter a shell on a emulated device: adb -s emulator-5554 shell Set screen-timeout to 30 Minutes: settings put system screen_off_timeout 1800000 Set date/time automatically: settings put global auto_time 1 Set chrome as default browser: settings put secure preferred_browser_package com.android.chrome Glossar Explanation of the different terms and files used in a Android Studio Project.\nGradle Is a build system usally used for Anroid-Apps.\nMore: https://developer.android.com/build/gradle-build-overview\nAndroid Debug Bridge (ADB) ",
    "categories": null
  },{
    "title": "Ansible",
    "url": "https://hmaier-dev.github.io/wiki/ansible/",
    "content": " ansible-playbook -i inventory.ini add_admin_user.yml ansible-playbook -i inventory.ini playbooks/deploy-traefik.yml Mit Vagrant Muss muss in der inventory.ini mit angeben, an welchem Ort sich der Private-Key befindet. Sonst kann Ansible sich nicht mit der VM verbinden.\n[test_machine] 192.168.56.10 ansible_ssh_user=vagrant ansible_ssh_private_key_file=.vagrant/machines/default/virtualbox/private_key missing sudo password Falls der Zieluser (ansible_ssh_user) auf dem System nicht root ist, muss dieser in der sudo-Gruppe sein, als auch sein Password mitgegeben werden. Dies tut man mit folgender Flag.\nansible-playbook -i inventory.ini basic_setup.yml --ask-become-pass Setup new Project Zur Vorbereitung auf ein neues Projekt sollte man als erstes den Zugang via ansible_user testen. Dafür deklariert man ein Inventory mit der IP-Adresse des Server sowie dem Namen des Users.\n## inventory.ini [all] 79.225.242.139 ansible_user=deploy Damit kann man dann ein AdHoc-Ping ausführen.\nansible -i inventory.ini all -m ping ## [ERROR]: Task failed: Failed to connect to the host via ssh: deploy@79.225.242.139: Permission denied (publickey,password). ## Origin: \u0026lt;adhoc \u0026#39;ping\u0026#39; task\u0026gt; ## ## {\u0026#39;action\u0026#39;: \u0026#39;ping\u0026#39;, \u0026#39;args\u0026#39;: {}, \u0026#39;timeout\u0026#39;: 0, \u0026#39;async_val\u0026#39;: 0, \u0026#39;poll\u0026#39;: 15} ## ## 79.225.242.139 | UNREACHABLE! =\u0026gt; { ## \u0026#34;changed\u0026#34;: false, ## \u0026#34;msg\u0026#34;: \u0026#34;Task failed: Failed to connect to the host via ssh: deploy@79.225.242.139: Permission denied (publickey,password).\u0026#34;, ## \u0026#34;unreachable\u0026#34;: true ## } Ansible versucht via SSH-Keys auf den Server zuzugreifen und schlägt fehl. Dies kann verschiedene Gründe haben, die mit einander zusammenhängen.\nUser deploy wurde noch nicht angelegt Der Public-Key der lokalen Maschine wurde noch nicht auf dem Server eingepflegt Dem kann man manuell (mit root-access) Abhilfe schaffen.\nuseradd deploy mkdir -p /home/deploy chown deploy:deploy /home/deploy Zurück auf der lokalen Maschine kann man ssh-copy-id verwenden, was den lokalen Public-Key auf dem Server unter /home/deploy/.ssh/authorized_keys einpflegt.\nssh-copy-id deploy@79.225.242.139 Nun kann man nochmal ein AdHoc-Ping versuchen.\nansible -i inventory.ini all -m ping ## 79.225.242.139 | SUCCESS =\u0026gt; { ## \u0026#34;ansible_facts\u0026#34;: { ## \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python3.11\u0026#34; ## }, ## \u0026#34;changed\u0026#34;: false, ## \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; ## } Secrets Secrets werden kann man in der gleichen Art und Weise behandeln wie Variablen. Der einzige Unterschied ist, dass man sein secrets.yml-File per Ansible-Vault verschlüsseln kann.\nansible-vault encrypt group_vars/all/secrets.yml Man wird nun nach einem Vault-Passwort gefragt, welches als Schlüssel dient. Weitere Variablen kann man mit edit hinzufügen:\nansible-vault encrypt group_vars/all/secrets.yml Die Datei kann wie folgt aussehen:\nkey1: secretkey key2: secretkey2##1?? Über vars_files importiert man den Vault nun wie auch andere Variablen.\nVault Password File Wenn man das Password nicht immer wieder eingeben möchte, kann man die Flag --vault-password-file \u0026lt;file\u0026gt; nutzen. Im File speichert man nur das Password ab und kann dann ein Playbook wie folgt ausführen:\nansible-playbook -i inventory.ini playbooks/deploy-authentik.yml --vault-password-file vault-env ",
    "categories": ["CI/CD"]
  },{
    "title": "apt",
    "url": "https://hmaier-dev.github.io/wiki/apt/",
    "content": "The Advanced Packaging Tool is a frontend for dpkg and is mostly used on debian-based distros.\nUnsupported architectures Viele Paket-Repos supporten nicht alle existierenden Architekutren:\nN: Skipping acquire of configured file \u0026#39;main/binary-i386/Packages\u0026#39; as repository \u0026#39;http://dl.google.com/linux/chrome/deb stable InRelease\u0026#39; doesn\u0026#39;t support architecture \u0026#39;i386\u0026#39; Diese Warnung kann man umgehen, wenn man die Architekture festzurrt:\ndeb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main Bei mehreren Variablen in den Brackets, einfach durch ein Leerzeichen trennen.\nSource: https://askubuntu.com/questions/741410/skipping-acquire-of-configured-file-main-binary-i386-packages-as-repository-x\nInformation über Paket Dabei ist apt-cache dein Freund.\n",
    "categories": ["linux"]
  },{
    "title": "Arch",
    "url": "https://hmaier-dev.github.io/wiki/arch/",
    "content": " \u0026times; Dualbooting with Windows With systemd-boot it is relativly easy to install Linux and Windows alongside. My suggestion would be to install Linux first and then make space for the Windows install. systemd-boot will automatically find all UEFI-partitions to boot from.\nOver the time, problems can occure because Windows will do ugly things to foreign partitions, when it updates. So be prepared.\nError Preparing initrd: Volume corrupted The Windows install will probably still boot.\nBoot with a live medium. Make a filesystem-check on the boot partition and approve the fix-prompt with: fsck /dev/sda1 Re-generate the boot-image with: mkinitcpio -P Reboot. pacman To ignore updates/replacement for a package, you can add it under options, e.g.:\n[options] IgnorePkg = ttf-sourcecodepro-nerd I already have nerd-fonts-source-code-pro installed via the AUR, so I ignore the native arch-package.\nHow to find non-used packages (orphans)? alias lsorphans=\u0026quot;sudo pacman -Qdt\u0026quot; How to remove non-used packages (orphans)? alias rmorphans=\u0026quot;pacman -Qtdq | sudo pacman -Rns -\u0026quot; Downgrading a package Für Notfälle hält pacman eine bestimmte Anzahl an alten Versionen einer Software im Cache (/var/cache/pacman/pkg/) vor.\nls /var/cache/pacman/pkg/ | grep \u0026#34;botan\u0026#34; Installieren tun man das Paket man mit der -U Flag.\npacman -U /var/cache/pacman/pkg/botan-3.9.0-1-x86_64.pkg.tar.zst Network You can do it different ways. Gnome uses NetworkManager by default. A less bloated way would be using the systemd-daemons for DNS and DHCP: systemd-networkd and systemd-resolved. Running the following script with the fitting $interface will give a basic config for using the network.\ninterface=eno1 touch /etc/systemd/network/20-wired.network echo \u0026#34;[Match]\u0026#34; \u0026gt;\u0026gt; /etc/systemd/network/20-wired.network echo \u0026#34;Name=$interface \u0026#34; \u0026gt;\u0026gt; /etc/systemd/network/20-wired.network echo \u0026#34; \u0026#34; \u0026gt;\u0026gt; /etc/systemd/network/20-wired.network echo \u0026#34;[Network]\u0026#34; \u0026gt;\u0026gt; /etc/systemd/network/20-wired.network echo \u0026#34;DHCP=yes\u0026#34; \u0026gt;\u0026gt; /etc/systemd/network/20-wired.network Static IP If your IP does not change, you can skip DHCP in the boot-process. You can configure a static IP as following in /etc/systemd/network/20-wired.network.\n[Match] Name=eno1 [Network] Address=192.168.178.110/24 Gateway=192.168.178.1 DNS=192.168.178.1 DNS Der einfachste Weg um den DNS-Server einzustellen, ist über die /etc/resolv.conf. Wenn man sytemd-resolved nutzt kann man auch /etc/systemd/resolv.conf editieren. Zu beachten ist, dass systemd-networkd und systemd-resolved beide DNS-Konfiguration erlauben. Unter diesem Artikel mehr dazu: https://wiki.archlinux.de/title/Systemd/systemd-resolved#systemd-networkd_vs._systemd-resolved\n",
    "categories": ["linux"]
  },{
    "title": "Authentik",
    "url": "https://hmaier-dev.github.io/wiki/authentik/",
    "content": "Installation Is kinda straight forward:\nhttps://docs.goauthentik.io/docs/install-config/install/docker-compose .env-file # ------------------------ # NOTE: this file needs to be called .env and not docker.env! # When named different PG_PASS cannot be set. I don\u0026#39;t know why... # # -------------------------------------- # For automated install AUTHENTIK_BOOTSTRAP_PASSWORD=qwertz1234 AUTHENTIK_BOOTSTRAP_TOKEN= AUTHENTIK_BOOTSTRAP_EMAIL=mail@server.de ## echo \u0026#34;AUTHENTIK_SECRET_KEY=$(openssl rand -base64 60 | tr -d \u0026#39;\\n\u0026#39;)\u0026#34; \u0026gt;\u0026gt; .env AUTHENTIK_SECRET_KEY=\u0026lt;key\u0026gt; ## Postgres ## echo \u0026#34;PG_PASS=$(openssl rand -base64 36 | tr -d \u0026#39;\\n\u0026#39;)\u0026#34; \u0026gt;\u0026gt; .env PG_PASS=\u0026lt;key\u0026gt; POSTGRES_USER=authentik POSTGRES_DB=authentik Bootstraping When deploying to public space you can use these variables at the worker-container to skip the OOB-experience:\nAUTHENTIK_BOOTSTRAP_PASSWORD AUTHENTIK_BOOTSTRAP_TOKEN AUTHENTIK_BOOTSTRAP_EMAIL By the way: The default user is call akadmin.\nRefernece: https://docs.goauthentik.io/docs/install-config/automated-install\nSitzungs Dauer einstellen Einerseits kann man am Provider die Gültigkeit des Tokens einstellen, andererseits kann man in der Phase (User Login Stage) die Sessionsdauer einstellen:\nhttps://www.reddit.com/r/Authentik/comments/1e6023h/noob_question_autologout_after_x_hours/ https://docs.goauthentik.io/docs/add-secure-apps/flows-stages/stages/user_login/ Wie genau diese beiden Parts zusammen hängen, muss ich noch verstehen.\nForwardAuth in Traefik Um vor jegliche Anwendung einen Authentifizierung zu setzen, kann man Authentik in Traefik als Middleware über ForwardAuth einbinden. Von Authentik selbst gibt es dazu eine passenden Anleitung.\nhttps://docs.goauthentik.io/docs/add-secure-apps/providers/proxy/server_traefik Wichtig ist, dass outpost.company:9000 mit dem Container-Namen des Authentik-Servers im traefik-net ersetzt wird. Zum Beispiel aus outpost.company:9000 wird authentik-server:9000. Dies ist der gleiche Name dem man dem Loadbalancer übergibt.\nIm Authentik müssen zudem noch ein Provider und eine Application angelegt werden. Zuletzt fügt man den Provider noch dem Embedded Outpost hinzu.\nReference:\nhttps://github.com/brokenscripts/authentik_traefik Session Duration https://docs.goauthentik.io/docs/add-secure-apps/flows-stages/stages/user_login/ LDAP Source Fürs Einbinden vom Active Directory gibt es eine eigene Anleitung:\nhttps://docs.goauthentik.io/docs/users-sources/sources/directory-sync/active-directory/ Troubleshooting Tokens To see the tokens saved on the location machine, go in your browser to Dev Tools \u0026gt; Application \u0026gt; Cookies.\n",
    "categories": null
  },{
    "title": "bash",
    "url": "https://hmaier-dev.github.io/wiki/bash/",
    "content": "TL;DR How to lock a account: usermod -L user (unlock it with -U) Nützliche Kommandos +set -o vi: vim-like movement in der aktivieren CTRL+R: Suche in der History. Mit \u0026lt;ESC\u0026gt; beenden. find . -type f | entr -r go run ./cmd/web: Führt Kommando erneut aus sobald sich ein Datei in einem Unterordner ändert. Colors and Effects in Terminal https://misc.flogisoft.com/bash/tip_colors_and_formatting if-else If you want to test a string, you can use\n-n to test if var is not empty -z to test if var is empty xargs Search for string in file list comming from a pipe.\ndfr ls-files | xargs grep \u0026#34;my searched string\u0026#34; xargs execute the following command on all received files.\n",
    "categories": ["cli"]
  },{
    "title": "crane",
    "url": "https://hmaier-dev.github.io/wiki/crane/",
    "content": "Ein Tool zum Arbeiten mit Container-Images und -Registrys. https://github.com/google/go-containerregistry/blob/main/cmd/crane/recipes.md\n",
    "categories": ["Container"]
  },{
    "title": "css",
    "url": "https://hmaier-dev.github.io/wiki/css/",
    "content": "This article covers mostly tailwindcss stuff but also vanilla.\nHow to exlude indirect children when working with :not()? main \u0026gt; *:not(.parallax) { @apply max-sm:px-2; } main \u0026gt; *:not(.parallax) * { @apply px-0; } This example is done with TailwindCSS.\nHow to expand div to the bottom fo the screen? There is h-screen with makes the div as high as the screen allows. If you have another div above for example a \u0026lt;header\u0026gt; you need to substract the height of \u0026lt;header\u0026gt; minus h-screen. This is how you do this:\n\u0026lt;header class=\u0026#34;h-16\u0026#34;\u0026gt; \u0026lt;!-- h-16 =\u0026gt; 4rem --\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;main class=\u0026#34;min-h-[calc(100vh-4rem)]\u0026#34;\u0026gt; \u0026lt;/main\u0026gt; This example is done with TailwindCSS.\nNumbering for header-tag On this website I found a trick how to use css for autonumbering:\nhttps://2ality.com/2012/01/numbering-headingshtml.html Completly without javascript (wow!).\nbody { counter-reset: h2counter h3counter h4counter h5counter h6counter; } h2::before { counter-increment: h2counter; content: counter(h2counter) \u0026#34;. \u0026#34;; counter-set: h3counter 0; } h3::before { counter-increment: h3counter; content: counter(h2counter) \u0026#34;.\u0026#34; counter(h3counter) \u0026#34;. \u0026#34;; counter-set: h4counter 0; } h4::before { counter-increment: h4counter; content: counter(h2counter) \u0026#34;.\u0026#34; counter(h3counter) \u0026#34;.\u0026#34; counter(h4counter) \u0026#34;. \u0026#34;; counter-set: h5counter 0; } h5::before { counter-increment: h5counter; content: counter(h2counter) \u0026#34;.\u0026#34; counter(h3counter) \u0026#34;.\u0026#34; counter(h4counter) \u0026#34;.\u0026#34; counter(h5counter) \u0026#34;. \u0026#34;; counter-set: h6counter 0; } h6::before { counter-increment: h6counter; content: counter(h2counter) \u0026#34;.\u0026#34; counter(h3counter) \u0026#34;.\u0026#34; counter(h4counter) \u0026#34;.\u0026#34; counter(h5counter) \u0026#34;.\u0026#34; counter(h6counter) \u0026#34;. \u0026#34;; } Tailwindcss v4.0 In v4.0 usually shouldn\u0026rsquo;t need to configure your content: https://tailwindcss.com/blog/tailwindcss-v4#automatic-content-detection\n",
    "categories": ["Web-Development"]
  },{
    "title": "Custom Windows Images",
    "url": "https://hmaier-dev.github.io/wiki/custom_windows_images/",
    "content": "Beim Bereitstellen von multiplen Maschinen mit Windows-Betriebssytem, wird man beim Durchleben von hohem zeitlichen Aufwand und der damit einhergehenden Lethargie, irgendwann anfangen nach Automatisierungs-Möglichkeiten zu forschen. Mit modifizierten Windows-Images kann man sich widerkehrende Installationsroutinen und Konfigurationen ersparen, und somit der Lethargie enfliehen.\nDoku von Mircosoft: https://learn.microsoft.com/de-de/windows-hardware/manufacture/desktop/windows-setup-automation-overview?view=windows-11 TL;DR Rechner mit jeglicher Software ausstatten Abbild des gesamten Systems erfassen ISO mit dem Abbild bauen System-Abbild auf weiteren Rechnern installieren Antwortdatien (unattend.xml,autounattend.xml) Um Einstellungen bei der Installation vorzudefinieren, kann man sich eine Antwortdatei (z.B.: autounattend.xml, unattend.xml) bauen. Diese wird in der ISO neben der setup.exe platziert. Da eine ISO ein fixe Größe hat, muss man jene entpacken, die Antwortdatei platzieren und danach mit oscdimg die ISO erneut gebaut werden. Hat man die standard Windows ISO auf C:\\ exthrahiert, muss die autounattend.xml hier liegen: C:\\Win10_22H2_German_x64v1\\autounattend.xml.\nZur Verifizierung der Antwortdatei kann der Windows System Image Manager (SIM) hilfreich sein.\nMir persönlich hat beim Erstellen von Antwort-Dateien folgende Website sehr geholfen:\nhttps://schneegans.de/windows/unattend-generator/ Aufbau Im Grund ist eine Antwortdatei wie folgt strukturiert:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;unattend xmlns=\u0026#34;urn:schemas-microsoft-com:unattend\u0026#34; xmlns:wcm=\u0026#34;http://schemas.microsoft.com/WMIConfig/2002/State\u0026#34;\u0026gt; \u0026lt;settings pass=\u0026#34;offlineServicing\u0026#34;\u0026gt;\u0026lt;/settings\u0026gt; \u0026lt;settings pass=\u0026#34;windowsPE\u0026#34;\u0026gt;\u0026lt;/settings\u0026gt; \u0026lt;settings pass=\u0026#34;generalize\u0026#34;\u0026gt;\u0026lt;/settings\u0026gt; \u0026lt;settings pass=\u0026#34;specialize\u0026#34;\u0026gt;\u0026lt;/settings\u0026gt; \u0026lt;settings pass=\u0026#34;auditSystem\u0026#34;\u0026gt;\u0026lt;/settings\u0026gt; \u0026lt;settings pass=\u0026#34;auditUser\u0026#34;\u0026gt;\u0026lt;/settings\u0026gt; \u0026lt;settings pass=\u0026#34;oobeSystem\u0026#34;\u0026gt;\u0026lt;/settings\u0026gt; \u0026lt;/unattend\u0026gt; In diesen Blöcken kann jeweils Konfiguration zu den 7 Phasen des Windows Setups deklariert werden.\nwindowsPE: In der Preinstallation Environment kann z.B. die Partitionierung des Systems oder auch das zu installierende Image angegeben werden. oobeSystem: Hier kann man Nutzer anlegen oder auch die verschiedenen Prompts (Telemetrie usw.) verstecken, die beim Windows Setup nerven. Unter diesem Link findet man die offizielle Dokumentation mit hilfreichem Schaubild: https://learn.microsoft.com/de-de/windows-hardware/manufacture/desktop/how-configuration-passes-work?view=windows-11\u0026amp;source=recommendations\nBeispiel Eine autounattend.xml kann wie folgt aussehen:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;unattend xmlns=\u0026#34;urn:schemas-microsoft-com:unattend\u0026#34; xmlns:wcm=\u0026#34;http://schemas.microsoft.com/WMIConfig/2002/State\u0026#34;\u0026gt; \u0026lt;!--https://schneegans.de/windows/unattend-generator/?LanguageMode=Unattended\u0026amp;UILanguage=de-DE\u0026amp;Locale=de-DE\u0026amp;Keyboard=00000407\u0026amp;GeoLocation=94\u0026amp;ProcessorArchitecture=amd64\u0026amp;ComputerNameMode=Random\u0026amp;CompactOsMode=Default\u0026amp;TimeZoneMode=Explicit\u0026amp;TimeZone=W.+Europe+Standard+Time\u0026amp;PartitionMode=Interactive\u0026amp;DiskAssertionMode=Skip\u0026amp;WindowsEditionMode=Generic\u0026amp;WindowsEdition=pro\u0026amp;UserAccountMode=Unattended\u0026amp;AccountName0=AdminLocal\u0026amp;AccountDisplayName0=AdminLocal\u0026amp;AccountPassword0=abelliocbc\u0026amp;AccountGroup0=Administrators\u0026amp;AccountName1=\u0026amp;AccountName2=\u0026amp;AccountName3=\u0026amp;AccountName4=\u0026amp;AutoLogonMode=Own\u0026amp;PasswordExpirationMode=Unlimited\u0026amp;LockoutMode=Disabled\u0026amp;HideFiles=Hidden\u0026amp;TaskbarSearch=Box\u0026amp;TaskbarIconsMode=Default\u0026amp;StartTilesMode=Default\u0026amp;StartPinsMode=Default\u0026amp;DisableDefender=true\u0026amp;DisableWindowsUpdate=true\u0026amp;TurnOffSystemSounds=true\u0026amp;DisableAppSuggestions=true\u0026amp;EffectsMode=Default\u0026amp;DesktopIconsMode=Default\u0026amp;WifiMode=Skip\u0026amp;ExpressSettings=DisableAll\u0026amp;KeysMode=Skip\u0026amp;ColorMode=Default\u0026amp;WallpaperMode=Default\u0026amp;WdacMode=Skip--\u0026gt; \u0026lt;settings pass=\u0026#34;offlineServicing\u0026#34;\u0026gt;\u0026lt;/settings\u0026gt; \u0026lt;settings pass=\u0026#34;windowsPE\u0026#34;\u0026gt; \u0026lt;component name=\u0026#34;Microsoft-Windows-International-Core-WinPE\u0026#34; processorArchitecture=\u0026#34;amd64\u0026#34; publicKeyToken=\u0026#34;31bf3856ad364e35\u0026#34; language=\u0026#34;neutral\u0026#34; versionScope=\u0026#34;nonSxS\u0026#34;\u0026gt; \u0026lt;SetupUILanguage\u0026gt; \u0026lt;UILanguage\u0026gt;de-DE\u0026lt;/UILanguage\u0026gt; \u0026lt;/SetupUILanguage\u0026gt; \u0026lt;InputLocale\u0026gt;0407:00000407\u0026lt;/InputLocale\u0026gt; \u0026lt;SystemLocale\u0026gt;de-DE\u0026lt;/SystemLocale\u0026gt; \u0026lt;UILanguage\u0026gt;de-DE\u0026lt;/UILanguage\u0026gt; \u0026lt;UserLocale\u0026gt;de-DE\u0026lt;/UserLocale\u0026gt; \u0026lt;/component\u0026gt; \u0026lt;component name=\u0026#34;Microsoft-Windows-Setup\u0026#34; processorArchitecture=\u0026#34;amd64\u0026#34; publicKeyToken=\u0026#34;31bf3856ad364e35\u0026#34; language=\u0026#34;neutral\u0026#34; versionScope=\u0026#34;nonSxS\u0026#34;\u0026gt; \u0026lt;UserData\u0026gt; \u0026lt;ProductKey\u0026gt; \u0026lt;Key\u0026gt;VK7JG-NPHTM-C97JM-9MPGT-3V66T\u0026lt;/Key\u0026gt; \u0026lt;WillShowUI\u0026gt;OnError\u0026lt;/WillShowUI\u0026gt; \u0026lt;/ProductKey\u0026gt; \u0026lt;AcceptEula\u0026gt;true\u0026lt;/AcceptEula\u0026gt; \u0026lt;/UserData\u0026gt; \u0026lt;ImageInstall\u0026gt; \u0026lt;OSImage\u0026gt; \u0026lt;InstallFrom\u0026gt; \u0026lt;MetaData wcm:action=\u0026#34;add\u0026#34;\u0026gt; \u0026lt;Key\u0026gt;/IMAGE/INDEX\u0026lt;/Key\u0026gt; \u0026lt;Value\u0026gt;1\u0026lt;/Value\u0026gt; \u0026lt;/MetaData\u0026gt; \u0026lt;/InstallFrom\u0026gt; \u0026lt;WillShowUI\u0026gt;OnError\u0026lt;/WillShowUI\u0026gt; \u0026lt;/OSImage\u0026gt; \u0026lt;/ImageInstall\u0026gt; \u0026lt;UseConfigurationSet\u0026gt;false\u0026lt;/UseConfigurationSet\u0026gt; \u0026lt;/component\u0026gt; \u0026lt;/settings\u0026gt; \u0026lt;settings pass=\u0026#34;generalize\u0026#34;\u0026gt;\u0026lt;/settings\u0026gt; \u0026lt;settings pass=\u0026#34;specialize\u0026#34;\u0026gt; \u0026lt;component name=\u0026#34;Microsoft-Windows-Shell-Setup\u0026#34; processorArchitecture=\u0026#34;amd64\u0026#34; publicKeyToken=\u0026#34;31bf3856ad364e35\u0026#34; language=\u0026#34;neutral\u0026#34; versionScope=\u0026#34;nonSxS\u0026#34;\u0026gt; \u0026lt;TimeZone\u0026gt;W. Europe Standard Time\u0026lt;/TimeZone\u0026gt; \u0026lt;/component\u0026gt; \u0026lt;/settings\u0026gt; \u0026lt;settings pass=\u0026#34;auditSystem\u0026#34;\u0026gt;\u0026lt;/settings\u0026gt; \u0026lt;settings pass=\u0026#34;auditUser\u0026#34;\u0026gt;\u0026lt;/settings\u0026gt; \u0026lt;settings pass=\u0026#34;oobeSystem\u0026#34;\u0026gt; \u0026lt;component name=\u0026#34;Microsoft-Windows-International-Core\u0026#34; processorArchitecture=\u0026#34;amd64\u0026#34; publicKeyToken=\u0026#34;31bf3856ad364e35\u0026#34; language=\u0026#34;neutral\u0026#34; versionScope=\u0026#34;nonSxS\u0026#34;\u0026gt; \u0026lt;InputLocale\u0026gt;0407:00000407\u0026lt;/InputLocale\u0026gt; \u0026lt;SystemLocale\u0026gt;de-DE\u0026lt;/SystemLocale\u0026gt; \u0026lt;UILanguage\u0026gt;de-DE\u0026lt;/UILanguage\u0026gt; \u0026lt;UserLocale\u0026gt;de-DE\u0026lt;/UserLocale\u0026gt; \u0026lt;/component\u0026gt; \u0026lt;component name=\u0026#34;Microsoft-Windows-Shell-Setup\u0026#34; processorArchitecture=\u0026#34;amd64\u0026#34; publicKeyToken=\u0026#34;31bf3856ad364e35\u0026#34; language=\u0026#34;neutral\u0026#34; versionScope=\u0026#34;nonSxS\u0026#34;\u0026gt; \u0026lt;UserAccounts\u0026gt; \u0026lt;LocalAccounts\u0026gt; \u0026lt;LocalAccount wcm:action=\u0026#34;add\u0026#34;\u0026gt; \u0026lt;Name\u0026gt;AdminLocal\u0026lt;/Name\u0026gt; \u0026lt;DisplayName\u0026gt;AdminLocal\u0026lt;/DisplayName\u0026gt; \u0026lt;Group\u0026gt;Administrators\u0026lt;/Group\u0026gt; \u0026lt;Password\u0026gt; \u0026lt;Value\u0026gt;supersecretpassword\u0026lt;/Value\u0026gt; \u0026lt;PlainText\u0026gt;true\u0026lt;/PlainText\u0026gt; \u0026lt;/Password\u0026gt; \u0026lt;/LocalAccount\u0026gt; \u0026lt;/LocalAccounts\u0026gt; \u0026lt;/UserAccounts\u0026gt; \u0026lt;OOBE\u0026gt; \u0026lt;ProtectYourPC\u0026gt;3\u0026lt;/ProtectYourPC\u0026gt; \u0026lt;HideEULAPage\u0026gt;true\u0026lt;/HideEULAPage\u0026gt; \u0026lt;HideWirelessSetupInOOBE\u0026gt;true\u0026lt;/HideWirelessSetupInOOBE\u0026gt; \u0026lt;HideOnlineAccountScreens\u0026gt;false\u0026lt;/HideOnlineAccountScreens\u0026gt; \u0026lt;/OOBE\u0026gt; \u0026lt;FirstLogonCommands\u0026gt; \u0026lt;SynchronousCommand wcm:action=\u0026#34;add\u0026#34;\u0026gt; \u0026lt;Order\u0026gt;1\u0026lt;/Order\u0026gt; \u0026lt;CommandLine\u0026gt;powershell.exe -WindowStyle Normal -NoProfile -Command \u0026#34;Get-Content -LiteralPath \u0026#39;C:\\Windows\\Setup\\Scripts\\FirstLogon.ps1\u0026#39; -Raw | Invoke-Expression;\u0026#34;\u0026lt;/CommandLine\u0026gt; \u0026lt;/SynchronousCommand\u0026gt; \u0026lt;/FirstLogonCommands\u0026gt; \u0026lt;/component\u0026gt; \u0026lt;/settings\u0026gt; \u0026lt;/unattend\u0026gt; Referenzen sysprep dism oscdimg FAQ Wie kommt man in die cmd während der Installation? SHIFT+F10 Interessante Projekte https://github.com/ntdevlabs/tiny11builder/blob/main/tiny11maker.ps1 Troubleshooting Das Abbild konnte nicht gefunden werden Die Setup.exe findet nicht das passende Abbild. Dieses muss daher extra angegeben werden. Die Info welchen Index unser Abbild hat bekommt man wie folgt:\ndism /Get-WimInfo /WimFile:install.wim ## Tool zur Imageverwaltung für die Bereitstellung ## Version: 10.0.19041.3636 ## ## Details für Abbild: \u0026#34;install.wim\u0026#34; ## ## Index: \u0026#34;1\u0026#34; ## Name: \u0026#34;Werkstatt Windows 10\u0026#34; ## Beschreibung: \u0026#34;\u0026lt;nicht definiert\u0026gt;\u0026#34; ## Größe: 32.922.249.198 Bytes ## ## Der Vorgang wurde erfolgreich beendet. Unter dem Key /IMAGE/INDEX kann man den Index als Value eintragen.\n\u0026lt;component name=\u0026#34;Microsoft-Windows-Setup\u0026#34; ...\u0026gt; \u0026lt;ImageInstall\u0026gt; \u0026lt;OSImage\u0026gt; \u0026lt;InstallFrom\u0026gt; \u0026lt;MetaData wcm:action=\u0026#34;add\u0026#34;\u0026gt; \u0026lt;Key\u0026gt;/IMAGE/INDEX\u0026lt;/Key\u0026gt; \u0026lt;Value\u0026gt;1\u0026lt;/Value\u0026gt; \u0026lt;/MetaData\u0026gt; \u0026lt;/InstallFrom\u0026gt; \u0026lt;WillShowUI\u0026gt;OnError\u0026lt;/WillShowUI\u0026gt; \u0026lt;/OSImage\u0026gt; \u0026lt;/ImageInstall\u0026gt; ",
    "categories": null
  },{
    "title": "cwebp",
    "url": "https://hmaier-dev.github.io/wiki/cwebp/",
    "content": "Installation Auf Windows über scoop installierbar.\nscoop install main/libwebp Anwendung cwebp -q 80 bild.jpg -o bild.webp Wandele alle jpeg um zu webp.\nparallel cwebp -q 80 {} -o {.}.webp ::: *.jpeg ",
    "categories": null
  },{
    "title": "dism.exe",
    "url": "https://hmaier-dev.github.io/wiki/dism/",
    "content": "Tool zur Imageverwaltung für die Bereitstellung\nCapture einer Installation Nach dem man die Installation mit sysprep.exe vorbereitet hat, booten man in eine WinPE-Umgebung und kann von dort das ein /capture-image anstoßen.\nDism /capture-image /imagefile:D:\\install-win10.wim /CaptureDir:C:\\ /Name:\u0026#34;Custom Windows 10 Image\u0026#34; Der Speicherort des /imagefile solle nach dem Herunterfahren der WinPE weiterhin erreichbar sein. Man nehme beispielweise einen USB-Stick oder mountet ein Netzlaufwerk.\nWinPE Zum Booten empfehle ich Venoty und als WinPE-Umgebung PhoenixPE.\nWim-File mounten Um Dateien einer wim-Datei hinzuzufügen oder eine ISO daraus zu erstellen, ist es nötig diese zu mounten.\ndism /Mount-Wim /WimFile:\u0026#34;C:\\Werkstatt_Service_Rechner\\install.wim\u0026#34; /index:1 /MountDir:C:\\mount Die Windows-Installation ist nun unter C:\\mount verfügbar.\nNach Abschluss der Arbeiten am Image, kann man wie folgt unmounten:\ndism /Unmount-Wim /MountDir:C:\\mount /Commit Apply einer Installation Hat man mit /Capture-Image ein Abbild aufgenommen, kann man es mit /Apply-Image direkt (ohne Erstellen einer ISO) auf eine Partition anwenden.\ndism /Apply-Image /ImageFile:E:\\imagefiles\\W7.wim /Index:1 /ApplyDir:C:\\ Dafür bietet es sich an sich über eine WinPE auf das System aufzuschalten. Von dort aus kann man das Wim-File auf die C:-Partition anwenden.\nGibt es hier die Meldung Der angegebene Pfadname ist ungültig. muss man ein chkdsk auf Quelle/Ziel anwenden.\nGet-WimInfo In einem WimFile können mehrere Windows-Versionen sein. Z.B.: Home aber auch Pro. Diesen werden durch einen Index gekennzeichnet.\ndism /Get-WimInfo /WimFile:C:\\Win7_Clean\\install.wim Es werden nun die verschiedenen Windows-Versionen inklusive Größe und Index ausgegeben.\nTool zur Imageverwaltung für die Bereitstellung Version: 10.0.26100.5074 Details für Abbild: \u0026#34;C:\\Win7_Clean\\install.wim\u0026#34; Index: \u0026#34;1\u0026#34; Name: \u0026#34;Windows 7 Home Basic\u0026#34; Beschreibung: \u0026#34;Windows 7 Home Basic\u0026#34; Größe: 11.623.452.494 Bytes Index: \u0026#34;2\u0026#34; Name: \u0026#34;Windows 7 Home Premium\u0026#34; Beschreibung: \u0026#34;Windows 7 Home Premium\u0026#34; Größe: 12.136.659.100 Bytes Index: \u0026#34;3\u0026#34; Name: \u0026#34;Windows 7 Professional\u0026#34; Beschreibung: \u0026#34;Windows 7 Professional\u0026#34; Größe: 12.037.929.390 Bytes Index: \u0026#34;4\u0026#34; Name: \u0026#34;Windows 7 Ultimate\u0026#34; Beschreibung: \u0026#34;Windows 7 Ultimate\u0026#34; Größe: 12.200.638.813 Bytes Der Vorgang wurde erfolgreich beendet. Features Offline hinzufügen Möchte man Features direkt nach der Installation verfügbar haben, kann man diese mit dism.exe vor der Installation dem Image hinzufügen.\nDafür benötigt man die install.wim die man unter \\sources\\install.wim findet. Diese hängt man nun mit folgenden Kommando ein.\ndism /Mount-Wim /WimFile:\u0026#34;C:\\W10_WST_1\\install.wim\u0026#34; /index:1 /MountDir:C:\\mount Danach kann man sich erstmal alle Features anzeigen lassen.\nDISM /Image:c:\\mount /Get-Features /Format:Table Möchte man bspw. .NET 3.5 aktiviert haben, führt man nun folgendes Kommando aus.\ndism /Image:C:\\mount /Enable-Feature /FeatureName:NetFx3 /All /Source:C:\\Win10_22H2_German_x64v1\\sources\\sxs /LimitAccess Als Source braucht man die Installationsquellen. Diese findet man in einer Windows-ISO unter \\sources\\sxs.\nNun kann man das Feature an sich nochmal abfragen, um sicherzugehen, dass es dem Image korrekt hinzugefügt worden ist.\ndism /Image:C:\\mount /Get-FeatureInfo /FeatureName:NetFx3 Zum Ende der Arbeiten an der install.wim muss man sie unmounten.\ndism /Unmount-Wim /MountDir:C:\\mount /Commit Um nun eine bootfähige ISO zu erhalten, nutzt man oscdimg.exe.\nExport einer Windows Version In der ISO die man von Microsoft herunterlädt, sind zahlreiche verschiedene Windows Versionen enthalten. Um ein Wim-File mit der einzigen gewollten Version zu erhalten, kann man diese Exportieren.\ndism /Export-Image /SourceImageFile:\u0026#34;D:\\sources\\install.wim\u0026#34; /SourceIndex:2 /DestinationImageFile:\u0026#34;D:\\sources\\install_clean.wim\u0026#34; /Compress:max /CheckIntegrity Troubleshooting Error 1243 Kann beim mounten einer install.wim auftreten. Mit diesen Registry-Einträgen kann man den Fehler lösen:\nWindows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\WIMMount] \u0026#34;DebugFlags\u0026#34;=dword:00000000 \u0026#34;Description\u0026#34;=\u0026#34;@%SystemRoot%\\\\system32\\\\drivers\\\\wimmount.sys,-102\u0026#34; \u0026#34;DisplayName\u0026#34;=\u0026#34;@%SystemRoot%\\\\system32\\\\drivers\\\\wimmount.sys,-101\u0026#34; \u0026#34;ErrorControl\u0026#34;=dword:00000001 \u0026#34;Group\u0026#34;=\u0026#34;FSFilter Infrastructure\u0026#34; \u0026#34;ImagePath\u0026#34;=hex(2):73,00,79,00,73,00,74,00,65,00,6d,00,33,00,32,00,5c,00,64,00,\\ 72,00,69,00,76,00,65,00,72,00,73,00,5c,00,77,00,69,00,6d,00,6d,00,6f,00,75,\\ 00,6e,00,74,00,2e,00,73,00,79,00,73,00,00,00 \u0026#34;Start\u0026#34;=dword:00000003 \u0026#34;SupportedFeatures\u0026#34;=dword:00000003 \u0026#34;Tag\u0026#34;=dword:00000001 \u0026#34;Type\u0026#34;=dword:00000002 [HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\WIMMount\\Instances] \u0026#34;DefaultInstance\u0026#34;=\u0026#34;WIMMount\u0026#34; [HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\WIMMount\\Instances\\WIMMount] \u0026#34;Altitude\u0026#34;=\u0026#34;180700\u0026#34; \u0026#34;Flags\u0026#34;=dword:00000000 Quelle ist dieser Artikel: https://answers.microsoft.com/en-us/windows/forum/all/solved-dismexe-error-1243-the-specified-service/836b860c-6427-40f9-9ea8-21869cd1218d\nWarum das funktioniert, ist mir nicht bekannt.\nError 161 Die Meldung dazu ist: Der angegebene Pfadname ist ungültig. Nach einen chdsk auf Quelle und Ziel funktioniert dism.exe.\nchkdsk E: /f chkdsk G: /f dism /capture-image /imagefile:E:\\image_folder\\image1.wim /capturedir:G:\\ /Name:\u0026#34;w7-important-image\u0026#34; ",
    "categories": null
  },{
    "title": "DNS",
    "url": "https://hmaier-dev.github.io/wiki/dns/",
    "content": "Special Domains .local Be careful if you are using macOS or Linux machines in your network. This domain is reserved for mDNS, which is like a plug-and-play DNS which doens\u0026rsquo;t need a DNS server.\n.dev In most browsers this domain is hardcoded t be used with HSTS. Don\u0026rsquo;t use it for your local domain running HTTP.\nBrave Browser If you locally configured DNS don\u0026rsquo;t work, you need to configure the DNS-Provider. By default it is OpenDNS. Under brave://settings/security you can set the OS-default as the DNS. Now the browser takes the same DNS as the ethernet-interface.\n",
    "categories": null
  },{
    "title": "Docker",
    "url": "https://hmaier-dev.github.io/wiki/docker/",
    "content": "TL;DR Dockerfile bauen: docker build --tag 'username/my-custom-name' . Alle Container; both running \u0026amp; stopped: docker ps -a Alle Container die gerade laufen: docker ps IP-Adresses aller Container: docker inspect -f '{{.Name}} - {{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' $(docker ps -q) Shell in Container öffnen docker exec -it \u0026lt;container_id_or_name\u0026gt; /bin/bash Directory in Container mounten: docker run -v \u0026lt;absolute-local-path\u0026gt;:\u0026lt;path-inside-container\u0026gt; \u0026lt;image\u0026gt; Einzelnen Container aus docker-compose-File neustarten docker compose up --no-deps \u0026lt;service-name\u0026gt; Herausfinden was sich in einem Volume alles befindet: docker run -it -v deploy-wordpress_wordpress:/mnt ubuntu /bin/bash Alle Container inklusive Volumen löschen: docker rm -vf $(docker ps -aq) Alle Images löschen docker rmi -f $(docker images -aq) Wie lade ich ein Image in meine Docker-Registry? Erst einloggen mit docker login. Danach docker push \u0026lt;username\u0026gt;/\u0026lt;image-name\u0026gt;:latest Wie erstelle ich ein neues :latest-image? Retag the old image: `docker tag \u0026lt;image_id\u0026gt; my-tool:previous`` Remove old latest tag: docker rmi my-tool:latest Build new image with latest: docker build -t checklist-tool:latest . Installation Install via apt: https://docs.docker.com/engine/install/debian/#install-using-the-repository Add user to Docker-Group: https://docs.docker.com/engine/install/linux-postinstall/\ndocker inspect Um Mehr Über das Image zu erfahren kann man mit\ndocker inspect \u0026lt;image:version\u0026gt; jegliche Daten ausgegeben kriegen, die von vom Ersteller:in eingegeben wurden.\nEntrypoint Möchte man das vorgegebene Verhalten, beim Starten des Containers, ändern, kann man den --entrypoint überschreiben. Dies kann hilfreich sein, wenn man sich bspw. nur das innere des Containers anschauen möchte ohne das irgendetwas gestartet wird.\nÜberschreiben mit der Bash-Shell würde wie folgt funktionieren:\ndocker run \\ --entrypoint /bin/bash \\ -it \\ \u0026lt;image:version\u0026gt; Das -it ist nötig, um ein Exit(0) des Containers zu verhindern. Exit(0) würde passieren, wenn die Shell merkt, dass sich niemand verbindet.\nOptimizing Image size Anstatt viele RUN-Kommandos zu verwenden, die jedes Mal einen neuen Layer aufmachen, bietet es sich an ein einziges RUN mit dem \u0026amp;\u0026amp;-Operator zu nehmen. Wenn du unschlüssige bist, warum der Container so riesige geworden ist, hilft ein\ndocker image history \u0026lt;img\u0026gt; Damit wird die Größe der einzelnen Layer angezeigt.\nGithub Container Registry You need to give the docker-command the permissions to access the Github-Container-Registry (ghcr). You do this via a Personal access token. Find the option for this under https://github.com/settings/tokens. The token needs the following permissions:\nwrite:packages delete:packages docker login ghcr.io -u \u0026lt;USER\u0026gt; --password \u0026lt;TOKEN\u0026gt; docker build . -t ghcr.io/user/repo:v0.1 docker push ghcr.io/user/repo:v0.1 You can now pull the image with\ndocker pull ghcr.io/user/repo:v0.1 More on this topic: https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry\nTroubleshooting Container stoppt langsam \u0026amp; gibt Exit Code 137 Die Binary die im Container läuft hat das SIGKILL nicht erhalten und Docker wartet eine vordefinierte Zeit lang bis er den Container runterfährt. Dabei wird die Binary (bzw. das Programm) nicht ordentlich geschlossen. Die Binary erhält das SIGKILL nicht, da sie nicht PID 1 ist. Das kann vorkommen, wenn man das Programm mit einem bash -c oder über CMD startet.\nAbhilfe schafft ENTRYPOINT im JSON-Format:\nENTRYPOINT [\u0026#34;./binary\u0026#34;, \u0026#34;-db\u0026#34;, \u0026#34;mysqlite.db\u0026#34;] Ob die Binary PID 1 ist, kann man testen in dem man im Container nachschaut (lol).\ndocker exec -it \u0026lt;container\u0026gt; ps aux ",
    "categories": ["Container"]
  },{
    "title": "Earthly",
    "url": "https://hmaier-dev.github.io/wiki/earthly/",
    "content": "Ist ein Buildtool welches Container nutzt, um die Toolchain bereit zustellen. Verschiedene Targets werden über ein sogennates Earthfile deklariert. Erinnern tut earthly dabei, an klassiche Makefiles.\nDer große Vorteil an earthly ist die Portabilität. Man kann seine CI-Pipeline lokal zusammenbauen und erhält bei Runs enau die gleichen Ergebnisse wie im Gitlab.\nEin einziges Target, welches Python-Skripte auf ihre Richtigkeit testet, kann beispielsweise so aussehen:\nsyntax-python: FROM python:3.12.3 # pullt python-image WORKDIR /src COPY --dir my/project/path container/path COPY some/other/dir/*.py container/path RUN find ./path -name \u0026#34;*.py\u0026#34; | xargs -t -P4 -n1 python3 -m py_compile Zusammen mit anderen Targets, kann dieses verkettet werden.\ntest-all: BUILD +syntax-go BUILD +syntax-python BUILD +syntax-bash BUILD +test-database SAVE ARTIFACT LOCALLY Dieses Kommando wird nur Dateien ins Host-Filesystem ausgeben, wenn die --ci-Flag nicht mitgegeben wurde (--help um zu erfahren was sie impliziert).\nSAVE ARTIFACT Möchte man Artifacts aus einem anderen Target importieren, kann man das wie folgt tun.\ntarget: COPY +download-hugo/\u0026lt;articfact\u0026gt; /path/to/copy/to COPY +download-hugo/hugo /usr/local/bin/hugo COPY +download-tailwindcss/tailwindcss /usr/local/bin/tailwindcss .secrets For deploying from your local machine, you need your secrets present in a .secrets file. That must be located in the same directory as the Earthfile. For multi-line secrets use '' like in the following example:\nhost=192.168.13.12 port=1337 username=secret-username key=\u0026#39;-----BEGIN OPENSSH PRIVATE KEY----- SOMEVALIDCHARACTERSWHICHMAKEUP AVERYGOODSECRETANDSAFEPRIVATEK -----END OPENSSH PRIVATE KEY-----\u0026#39; known_hosts=\u0026#39;content-of-the-known-hosts-file\u0026#39; The '' are needed because they keep the format (like newlines etc).\nErrors Error: could not determine buildkit address - is Docker or Podman running? If you encounter this error, first look if the systemd-service is running.\nsystemctl status docker.service If it is, you/Earthly probably don\u0026rsquo;t have sufficient rights to call docker. You can test this, by manually calling docker without sudo/doas.\ndocker ps -a # Output: # permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: # Get \u0026#34;http://%2Fvar%2Frun%2Fdocker.sock/v1.46/containers/json?all=1\u0026#34;: # dial unix /var/run/docker.sock: connect: permission denied The solution to this problem, is to add your user-group to the docker group.\nsudo usermod -aG docker \u0026lt;username\u0026gt; failed to stat parent: stat /tmp/earthly/buildkit/runc-overlayfs/snapshots/snapshots/2006/fs: no such file or directory Something with the cache was wrong. I resolved the issue with: earthly prune -a which cleared the cache.\nMore on how to manage the cache:\nhttps://docs.earthly.dev/docs/caching/managing-cache ",
    "categories": ["CI/CD"]
  },{
    "title": "ffmpeg",
    "url": "https://hmaier-dev.github.io/wiki/ffmpeg/",
    "content": "Converting filetypes If you want to convert a single ogg-file into mp3.\nffmpeg -i \u0026#34;file.ogg\u0026#34; \u0026#34;file.mp3\u0026#34; If there are multiple files, instead of writing a script, you could use gnu/parallel to use all of your CPU cores.\nparallel ffmpeg -i \u0026#34;{}\u0026#34; \u0026#34;{.}.mp3\u0026#34; ::: *.ogg Changing bitrate ffmpeg -i sounds.mp3 -b:a 128k sounds.mp3 These are the different bitrates.\n32 kbps: Very low quality, generally used for voice recordings or very small files. 64 kbps: Low quality, suitable for voice recordings and some music where size is a significant concern. 96 kbps: Moderate quality, often used for streaming audio over low-bandwidth connections. 128 kbps: Standard quality, often considered the minimum acceptable quality for music. A common choice for streaming and digital downloads. 160 kbps: Above average quality, providing better sound than 128 kbps but with a slightly larger file size. 192 kbps: Good quality, often used for higher-quality music streaming and digital downloads. 224 kbps: Higher quality, offering better audio fidelity than 192 kbps. 256 kbps: High quality, used for better sound reproduction, often used in high-quality digital downloads. 320 kbps: Highest quality for MP3, offering the best audio fidelity, often indistinguishable from the original CD-quality sound. ",
    "categories": ["cli","Linux"]
  },{
    "title": "gh",
    "url": "https://hmaier-dev.github.io/wiki/gh/",
    "content": "If port 22 isn\u0026rsquo;t available in your network and you cannot use key-pairs to authenticate to github. You can use the internal github-tool gh, which uses https.\nmultiple accounts https://github.blog/changelog/2023-12-18-log-in-to-multiple-github-accounts-with-the-cli/ switch accounts gh auth status repo not found Can happen if switch accounts. Re-auth with this command:\ngh auth refresh -h github.com -s repo ",
    "categories": ["cli"]
  },{
    "title": "git",
    "url": "https://hmaier-dev.github.io/wiki/git/",
    "content": "TL;DR Ich möchte alles rückgängig machen was ich bisher gemacht habe: reset --hard Ich habe ungewollte Commits in meinem Branch: rebase -i \u0026lt;commit-hash\u0026gt;^ Das Circumflex macht den rebase --interactive inklusiv. Es gibt den Parent des Commits an, und nimmt den angegebenen Commit daher in den rebase -i mit hinein. Ich muss nachträglich Änderungen zu einem Commit hinzufügen: commit --fixup \u0026lt;commit\u0026gt; und rebase -i --autosquash Ich möchte Änderungen aus dem Hauptbranch (z.B. production) in meinem branch übernehmen: git pull \u0026amp;\u0026amp; git rebase production Wie kann ich ein Commit zu mehreren umwandeln: rebase -i \u0026amp;\u0026amp; edit \u0026lt;jeweiligen-commit\u0026gt; \u0026amp;\u0026amp; add -p Wie erstelle ich einen neuen Branch?: checkout \u0026lt;main/prod\u0026gt; \u0026amp;\u0026amp; switch -c \u0026lt;new-branch\u0026gt; Ich ein rebase -i auf meinen kompletten Branch machen: git rebase -i HEAD~$( git rev-list --count --no-merges \u0026lt;main\u0026gt;..) Bezieht den allerste Commit mit ein: git rebase -i --root Wie übernehme ich einzelne Commits in meinen Branch: git switch \u0026lt;mein-branch\u0026gt; \u0026amp;\u0026amp; git cherry-pick \u0026lt;commit-hash\u0026gt; Wie sehe ich alle Änderungen in einer Datei auf Zeit?: git log -p production.. -- \u0026lt;file\u0026gt; Wie kann ich den letzten Commit, von meiner derzeitigen Position, auseinander-basteln? git reset HEAD~ Kann man mit nem rebase -i kombinieren, da dabei der HEAD ja durch die Commits wandert. Einfach im Editor mit edit am gewünschten Commit anhalten und dann reseten. Wie kann ich ein gelöschtes File wiederherstellen. git checkout \u0026lt;commit-hash\u0026gt;^ -- \u0026lt;filename\u0026gt; git add \u0026lt;filename\u0026gt; This feature helps Git remember how you resolved conflicts previously, so if the same conflict arises again, Git can automatically apply the same resolution. git config --global rerere.enabled true Wie kriege ich mein lokales Repo auf den Stand des Remote-Repos? Falls origin main ist: git rebase origin/main Welches ist Remote-Repo? git branch -a um alle Branches zu sehen. Um nur die Remote-Branches zu sehen ein git branch -r Wie arbeite ich mit meinem Remote-Branch lokal? Zuerst, alle Remote-Branches anzeigen lasse: git branch -r Dann, neuen lokalen Branch auf Remote-Branch als Startpunkt zeigen lassen: git checkout -b \u0026lt;branch\u0026gt; origin/\u0026lt;branch\u0026gt; Wie finde ich den Commit mit dem eine Änderung an einer Zeile gemacht wurde? git blame -L \u0026lt;begin\u0026gt;,\u0026lt;end\u0026gt; -- \u0026lt;path/to/file\u0026gt; Für jede einzelne Zeile im Bereich (inklusiv) wird der kurze Commit angezeigt. Über ein git show \u0026lt;commit\u0026gt; findet man den den jeweiligen Commit. rebase Mit einem rebase \u0026lt;main\u0026gt; bringt man den Branch auf die Höhe des Hauptbranches.\nFalls man eine Branch versaut hat und dieser schon als Merge-Request im Gitlab steht, kann man die ganze Sache mit nem rebase -i bereinigen.\nDazu nehme man den letzten Commit in dem Branch bevor, die Sauerei angefangen hat und geben starte damit den rebase: git rebase -i \u0026lt;commit\u0026gt;.\nMan wird nun in ein Editor geworfen in dem man Commits ändern oder auch entfernen kann. Nach dem Schließen des Editors kann man dem versauten Zustand mit nem git pull wiederherstellen oder mit nem git push origin \u0026lt;versaubeutelter-branch\u0026gt; --force den Merge-Request aktualisieren.\nWas bei einem rebase wichtig zu beachten ist, dass sich die Commit-IDs ändern. Zwei unterschiedliche Commits mit den gleichen Änderungen gehören somit dann nicht mehr zusammen.\nreset Falls man schon getätigte Commits wieder rückgängig machen möchte, kann man dies mit git reset --hard \u0026lt;commit\u0026gt; machen. Der angegebene Commit ist dabei der, auf welchen man zurück möchte. Möchte man diesen inklusive löschen, gibt man einfach den Commit mit Circumflex (\u0026lt;commit\u0026gt;^) an.\nAllerdings ist dieses Kommando mit Vorsicht zu genießen, den alle neueren Commit werden gelöscht.\nreflog Vorherige Stände des Branch anziegn.\nmerge Habe ich einen Hauptbranch (z.B. main) und möchte eine Nebenbranch (z.B. wichtiges-feature1) mergen, bietet es sich an wichtiges-feature1 zu allererst mit einem rebase auf den Stand des Hauptbranches zu bringen.\ngit checkout wichtiges-feature1 git rebase main Wenn alle potenziellen Konflikte bereinigt sind, kann ich mergen. Dazu gehe ich in den Hautpbranch und merge dort.\ngit checkout main git merge wichtiges-feature1 Danach kann ich den Nebenbranch löschen.\ngit branch -d wichtiges-feature1 Beim mergen ist zu beachten, dass beide Branches lokal vorhanden sind.\nadd --patch Falls ich in einem File Änderungen gemacht habe, die verschiedenen Commits zugehörig sind, kann ich dies mit einem --patch bzw. -p machen. Git teilt das File dann in Blöcke ein, die es für sinnig befindet. Das heißt nicht, dass die Einteilung immer sinnig ist. Allerdings kann man diese auch nachbearbeiten.\n# Alle Optionen beim git add -p Diesen Patch-Block der Staging-Area hinzufügen [y,n,q,a,d,j,J,g,/,e,?]? commit --fixup Falls man im Nachhinein einem Commit Änderungen hinzufügen möchte und die Commit-ID parat hat, kann man dies mit eine --fixup machen. Danach ist ein rebase -i --autosquash \u0026lt;base-branch\u0026gt; nötig. Dabei werden dem \u0026lt;commit\u0026gt; die darunterliegenden Commits mit squash hinzugefügt.\ncommits spliten Diese manpage ist ziemlich hilfreich dabei: https://manpages.debian.org/bookworm/git-man/git-rebase.1.en.html#SPLITTING_COMMITS.\nWährend des rebase kann mit add -p verschiedene Code-Stücke in einzelne Commits übernehmen.\nupdate-refs update-ref refs/heads/\u0026lt;your-branch\u0026gt; Einzelne Commits für MR fertig machen Variante 1 (cherry-pick) Da ein MR einfach nur ein Branch ist, erstellt man einen seperaten Branch in den man per cherry-pick die gewünschten Commits kopiert. Die gepickten Commits werden kopiert und nicht verschoben (sie existieren nun auf beiden Branches). Hier ist ein möglicher Ablauf mit cherry-pick:\n# Beim Checkout neuen Branch anlegen git checkout -b \u0026lt;neuer-branch\u0026gt; origin/production git cherry-pick \u0026lt;commit-hash1\u0026gt; git cherry-pick \u0026lt;commit-hash2\u0026gt; git push -u origin Beim cherry-pick kann es durchaus zu Merge-Konflikten kommen. Bespielweise wenn man verschiedene Commits von Änderungen an einen File pickt, die von einander abhängen.\nMan könnte natürlich auch den gesamten Branch kopieren und mit einem rebase -i alle Commits entfernen die nicht passend sind.\n# Nimmt derzeitigen Branch als base git checkout -b \u0026lt;neuer-branch\u0026gt; # Nimmt production als base-branch git checkout -B \u0026lt;neuer-branch\u0026gt; production Variante 2 (update-refs) Ab der Version 2.38, kann man in einem interactive rebase den Command update-ref refs/heads/\u0026lt;anderer-branch\u0026gt; angeben. Damit kann man entweder auf einen bestehenden Branch verweisen oder einen neuen Branch anlegen. Diese ist dann als Referenz zum base-Branch. Man zweigt also Commits in seperate Branches ab, kann man aber bei nem rebase vom base-Branch dessen Änderungen übernehmen.\nMR/PR löschen Da ein Merge-/Pull-Request im Grunde nichts anderes als ein Branch ist, kann man ihn wie folgt löschen:\n# Lösche den Remote-Branch (ersetze origin durch den Namen deines Remotes) git push origin --delete \u0026lt;dein-branch\u0026gt; # Wechsle zu einem anderen Branch, um sicherzustellen, dass der zu löschende Branch nicht aktiv ist git checkout \u0026lt;anderer-branch\u0026gt; # Lösche den lokalen Branch git branch -d \u0026lt;dein-branch\u0026gt; Submodule Repositorys Bei manchen Repositorys werden anderer Repos mit eingebunden. Ab und an kann man ein solche Nachricht krigen:\nAuf Branch main Ihr Branch ist auf demselben Stand wie \u0026#39;origin/main\u0026#39;. Änderungen, die nicht zum Commit vorgemerkt sind: (benutzen Sie \u0026#34;git add \u0026lt;Datei\u0026gt;...\u0026#34;, um die Änderungen zum Commit vorzumerken) (benutzen Sie \u0026#34;git restore \u0026lt;Datei\u0026gt;...\u0026#34;, um die Änderungen im Arbeitsverzeichnis zu verwerfen) geändert: file.mod/pkg/myfile (neue Commits) Unversionierte Dateien: (benutzen Sie \u0026#34;git add \u0026lt;Datei\u0026gt;...\u0026#34;, um die Änderungen zum Commit vorzumerken) Mit dem (neue Commits) wird darauf hingewiesen, das eingebettete Repo einmal mit git submodule update auf den neusten Stand zu bringen.\n--bare Mit einem bare-Repository kann man einen selbstgewählten --work-tree benutzen. Man kann beispielweise dafür sein $HOME nehmen, um damit Configs, Dotfiles, etc. zu verwalten. Dafür benutzt man dann diesen alias.\n/usr/bin/git --git-dir=$HOME/repos/dotfiles/ --work-tree=$HOME Die Einrichtung dieses Setups zum Verwalten von Dotfiles läuft wie folgt.\ngit config --global init.defaultBranch main mkdir -p $HOME/repos git clone --bare https://github.com/hmaier-dev/dotfiles.git $HOME/repos/dotfiles # oder # git clone --bare git@github.com:hmaier-dev/dotfiles.git $HOME/repos/dotfiles git --git-dir=$HOME/repos/dotfiles/ --work-tree=$HOME config --local status.showUntrackedFiles no git --git-dir=$HOME/repos/dotfiles/ --work-tree=$HOME checkout main git --git-dir=$HOME/repos/dotfiles/ --work-tree=$HOME push --set-upstream origin main Vorher sollte $HOME am besten komplett blank sein (also auch ohne .bashrc etc.), damit es nicht zu Merge-Konflikten kommt.\nconfig Diese Variable kann gesetzt werden, wenn git-diff immer sein eigenes vim nimmt.\ngit config --global core.editor nvim Plattformen Github Gitlab https://forgejo.org/ ",
    "categories": ["cli","Linux","ci/cd"]
  },{
    "title": "Github",
    "url": "https://hmaier-dev.github.io/wiki/github/",
    "content": "Actions Setting up ssh access for runner to vm You will need create a key-pair. On the runner you will need the private key and on the vm the public key.\nid_rsa goes into e.g. {{ secrets.SSH_KEY }} id_rsa.pub goes into ~/.ssh/authorized_keys on the vm Best practice would be to create the user on your local machine and distribute the keys from there.\nuseradd deploy passwd deploy su deploy ssh-keygen -t ed25519 -a 200 -C \u0026#34;runner@github.com\u0026#34; ls -la ~/.ssh Updating static html on vm When ssh is setup right, you can over the files with rsync.\nrsync -rav ./public deploy@vm:~/\u0026lt;dir-for-html\u0026gt; The deploying user (e.g. deploy) must be in the same group as nginx user (e.g. Group: www-data). You achieve this by:\nusermod -a -G www-data deploy To ensure all files have the right ownership, set the setgid-bit on the \u0026lt;dir-for-html\u0026gt;.\nchmod -R g+s \u0026lt;dir-for-html\u0026gt; Enabling debugging for steps If you need more insign into, what is happening, you can enable debugging for the job.\njobs: deploy: runs-on: ubuntu-24.04 env: ACTIONS_STEP_DEBUG: true Secrets When passing multi-line secrets, make sure to border the secret with \u0026quot; like this:\nearthly --secret host=${{ secrets.SSH_HOST }} \\ --secret username=${{ secrets.SSH_USER }} \\ --secret key=\u0026#34;${{ secrets.SSH_KEY }}\u0026#34; \\ +deploy-test The \u0026quot; keeps the format in it\u0026rsquo;s right place.\nCaching With certain actions you can cache binaries or docker-images instead of downloading them each run. This makes your builds much faster.\nCaching Docker-Images This a action (there a many) you can use for caching a docker file.\n- name: Cache Docker images for earthly uses: ScribeMD/docker-cache@0.5.0 with: key: docker-${{ runner.os }}-${{ hashFiles(\u0026#39;Earthfile\u0026#39;) }} You can use the hashfiles-function to generate a unique hash, to keep your caches apart. For generating the hash you should use the file, in which you declare your used image. In case of Docker that could be:\ndocker-compose.yml Dockerfile Earthfile etc. Caching binaries For binaries the caching can be done, within some steps. In this example caching of the earthly-binary is done.\n# Step 1 - name: Setup cache for earthly binary id: earthly-binary uses: actions/cache@v4 with: path: /opt/earthly/v0.8.13 # If version changes, a new binary will be downloaded key: earthly-${{ runner.os }}-${{ env.EARTHLY_VERSION }} # Step 2 - name: Download Binary if Not Cached if: steps.earthly-binary.outputs.cache-hit != \u0026#39;true\u0026#39; run: | mkdir -p \u0026#34;$EARTHLY_PATH\u0026#34; curl -L -o \u0026#34;$EARTHLY_PATH\u0026#34;/earthly https://github.com/earthly/earthly/releases/download/$EARTHLY_VERSION/earthly-linux-amd64 chmod +x $EARTHLY_PATH/earthly # Step 3 - name: Add earthly to PATH run: echo \u0026#34;$EARTHLY_PATH\u0026#34; \u0026gt;\u0026gt; $GITHUB_PATH # Step 4 - name: Check if earthly is in path run: earthly --version Step 2 will just run and download the binary, if no key has been found. A good place to store binaries that are not installed by the systems package manager is /opt. In this example the semantic is /opt/\u0026lt;name\u0026gt;/\u0026lt;version\u0026gt; (e.g. /opt/earthly/v0.8.13). Add the path to $GITHUB_PATH to make the binary everywhere available.\nThe key of the cache (Step 1) needs to have a unique part. So you can keep different version apart. For the binary I just use the version number.\nPackages Ressources: https://docs.github.com/en/packages/learn-github-packages/introduction-to-github-packages How this wiki works The wiki files are stored in my private dotfiles repository. Since I prefer to keep this repository private, but GitHub Pages requires a public repository, I push the necessary files to a separate public repository for publishing.\nCommitting Changes to the Private Repository Any changes made in docs/vimwiki are committed and pushed to the private remote repository.\nSyncing to the Public Repository A GitHub Actions workflow automates the process of syncing changes to the public repository. Here\u0026rsquo;s how it works:\nThe workflow clones the public wiki repository.\nIt updates the specified files based on a whitelist.\nFinally, it commits and pushes the changes back to the public repository.\nThe workflow located in ~/.github/workflow/wiki.yml looks like this:\nname: Update all wiki articles on: push: branches: - main paths: - docs/vimwiki/** jobs: publish: runs-on: ubuntu-latest defaults: run: working-directory: ./docs/vimwiki env: content: ./wiki/content steps: - uses: actions/checkout@v4 - name: Cloning repo env: # Github personal access token TOKEN: ${{ secrets.WIKI_REPO_TOKEN_RW }} run: | git config --global user.email \u0026#34;\u0026lt;\u0026gt;\u0026#34; git config --global user.name \u0026#34;Github Actions Runner\u0026#34; git clone --single-branch --branch main \\ \u0026#34;https://x-access-token:$TOKEN@github.com/hmaier-dev/wiki.git\u0026#34; \u0026#34;wiki\u0026#34; - name: Removing old files run: | find $content -name \u0026#39;*.md\u0026#39; -type f -exec rm {} \\; ls -la - name: Copy over new files run: | # Whitelist of all publishable wiki articles cp index.md $content # some more markdown files... # Pushing to the public wiki - name: Commit and push new files run: | cd wiki git checkout main git add . git diff-index --quiet HEAD || git commit -m \u0026#34;Automatic wiki-publish\u0026#34; git push origin main Access Token Setup To enable this process, you need a GitHub personal access token with repo permissions. You can generate one at GitHub Settings \u0026gt; Tokens. When cloning the public repository, the token is passed as part of the URL, like this:\ngit clone --single-branch --branch main \\ \u0026#34;https://x-access-token:$TOKEN@github.com/user/public-repo.git\u0026#34; \u0026#34;repo\u0026#34; Publishing via Hugo When the changes arrive in the public-repository, the publish.yml workflow is triggered. Running the workflow sets up earthly and uses it running hugo and publishes the generated html to the github-pages.\nEarthly Earthly is like a Makefile for CI. All logic is declared in the Earthfile. This file enables me to declare different targets, which every of them spawns a docker-container. By using Earthly I can run my CI locally without waiting for a runner.\nVERSION 0.8 hugo: FROM alpine:3.20 RUN apk add --no-cache hugo # Hugo cannot work in root (/) WORKDIR tmp COPY content content COPY static static COPY hugo.toml hugo.toml COPY layouts layouts RUN mv content/index.md content/_index.md RUN hugo RUN ls -la public SAVE ARTIFACT ./public AS LOCAL ./public build: BUILD +hugo The generated html-files are getting exporter to ./public, which is the publish_dir for Github-Pages.\n",
    "categories": ["CI/CD"]
  },{
    "title": "Gitlab",
    "url": "https://hmaier-dev.github.io/wiki/gitlab/",
    "content": "Include a foreign job include: - remote: https://gitlab.com/repo/dir/-/raw/version/jobs.yml stages: - test - deploy - apply test: stage: test extends: [.gj_earthly] script: - earthly --no-output +test only: - branches except: - production extends: Inherits this job (could be keept in a seperate file and imported) e.g.: gj_earthly is keept in a different repo in the jobs.yml which is imported at the top only/except: https://docs.gitlab.com/ee/ci/yaml/#only--except Basic Syntax: https://docs.gitlab.com/ee/ci/yaml/\n",
    "categories": ["CI/CD"]
  },{
    "title": "Gnome",
    "url": "https://hmaier-dev.github.io/wiki/gnome/",
    "content": "System-Tray By default Gnome 45 does not provide a build in system-tray, where application like steam, can display their tray icon. The people from ubuntu provide a solution to this, with the gnome-shell-extension-appindicator. It can be found in the AUR under gnome-shell-extension-appindicator-git.\nChanging the default terminal emulator You can do this, with the following command:\nsudo update-alternatives --config x-terminal-emulator ",
    "categories": ["Linux"]
  },{
    "title": "GNU/Linux",
    "url": "https://hmaier-dev.github.io/wiki/linux/",
    "content": "See disk usage ncdu Encrypting block devices The standard way on linux is to use LUKS.\nWindows On Windows LUKS-encrypted block devices can be accessed with https://en.wikipedia.org/wiki/FreeOTFE\n",
    "categories": ["Linux"]
  },{
    "title": "Golang",
    "url": "https://hmaier-dev.github.io/wiki/golang/",
    "content": "Go ist eine kompilierte Sprache die von Google entwickelt wurde.\nImports Go mag keine relativen Imports. Daher muss immer der absolute Pfad angeben werden.\nimport ( // Module befindet sich in ./pkg/loading \u0026#34;github.com/hmaier-dev/contacts_converter/pkg/loading\u0026#34; // Falsch wäre: \u0026#34;../pkg/loading\u0026#34; ) Ein Underscore stellt eine Blank-Import dar. Das heißt, man selbst greift nicht auf das Module zu, sondern andere Module die man importiert hat. Man sieht dies bspw. beim Import eines SQLite-Drivers\nimport ( \u0026#34;database/sql\u0026#34; _ \u0026#34;github.com/mattn/go-sqlite3\u0026#34; // needed for database/sql when working with sqlite3 ) Schlafende Go-Routine neustarten Ich bin heute auf den Fall gestoßen, eine schlafende Go-Routine neustarten zu müssen. Da man time.Sleep(d) nicht unterbrechen, bzw. nicht zum Aufwecken zwingen kann, benutzt man daher time.After(d).\ntime.After(d) macht einen Channel auf, den man zusammen mit dem Channel, über welchen man sein Signal senden möchte, an ein select-Statement andockt. select hört nun beide Channels ab und führt bei eintreffen eines Signals, den jeweiligen Logik-Block aus.\nvar restartSignal = make(chan bool) func main() { go maintain() for{ time.Sleep(time.Second * 7) restartSignal \u0026lt;- true fmt.Println(\u0026#34;Lets restart!\u0026#34;) close(restartSignal) // alten Channel schließen restartSignal = make(chan bool) //neuen Channel öffnen go maintain() } } func maintain() { count := 0 for{ count++ fmt.Printf(\u0026#34;Iteration.. %d\\n\u0026#34;, count) select{ case \u0026lt;-restartSignal: return // Funktion beenden case \u0026lt;-time.After(time.Second * 3): break // Aus select ausbrechen und nächste Iteration einleiten } } } Modules forken Hat man ein Module was nicht so funktioniert, wie man es möchte, macht man sich einfach einen Fork davon. Nun hat man die Macht Änderungen um Code vorzunehmen. Sollen diese Änderungen direkt im Hauptprojekt nutzbar sein, kann man das geforkte Repository klonen und Go dazu bringen, dies zu nutzen. Dies tut man in der go.mod mit dem replace-Kommando.\nrequire ( github.com/emersion/go-vcard v0.0.0-00010101000000-000000000000 ) replace github.com/emersion/go-vcard =\u0026gt; ../go-vcard Den Pfad des geforkten Repositorys muss man von den root des Hauptprojekts angeben.\nDatenbanken Initialzing connection To work with databases you need\nfunc Init() *sql.DB { db, err := sql.Open(\u0026#34;sqlite3\u0026#34;, \u0026#34;/opt/tool/sqlite.db\u0026#34;) if err != nil { log.Fatal(\u0026#34;Failed to connect to database:\u0026#34;, err) } // Create the devices table if it doesn\u0026#39;t exist createStmt := ` CREATE TABLE IF NOT EXISTS nice_table ( id INTEGER PRIMARY KEY AUTOINCREMENT, important_data TEXT ); ` _, err = db.Exec(createStmt) if err != nil { log.Fatal(\u0026#34;Failed to create table:\u0026#34;, err) } return db } Instead of return *sql.DB you could also create a global variable.\nvar db *sql.DB Scan into struct func GetDataByID(db *sql.DB, id int)(*data.Entry, error){ query := `SELECT imei, name, ticket, model, yaml FROM checklists WHERE id = ?` row := db.QueryRow(query, id) var singleEntry data.Entry err := row.Scan(\u0026amp;singleEntry.IMEI, \u0026amp;singleEntry.Name, \u0026amp;singleEntry.Ticket, \u0026amp;singleEntry.Model, \u0026amp;singleEntry.Yaml) if err != nil { if err == sql.ErrNoRows { log.Printf(\u0026#34;No entry found for ID %s\u0026#34;, id) return nil, nil } log.Fatal(\u0026#34;Failed to scan entry:\u0026#34;, err) return nil, err } return \u0026amp;singleEntry, nil } Select * from table This is not so easy as you think. Because you need a fixed destination for the values you received by rows.Scan.\ndb, err := sql.Open(\u0026#34;sqlite3\u0026#34;, source) if err != nil{ fmt.Println(err) } rows, err := db.Query(\u0026#34;Select * from table;\u0026#34;) if err != nil{ log.Fatalf(\u0026#34;%#v\\n\u0026#34;, err) } cols, err := rows.Columns() if err != nil{ log.Fatalf(\u0026#34;%#v\\n\u0026#34;, err) } rawResult := make([][]byte, len(cols)) // [row][values] -\u0026gt; e.g. row: [[value][value][value]] dest := make([]interface{}, len(cols)) // .Scan() needs []any as result type allRows := make([][]string, 0) for i := range cols { dest[i] = \u0026amp;rawResult[i] // mapping dest indices to byte slice } for rows.Next() { err := rows.Scan(dest...) if err != nil { log.Fatal(\u0026#34;problems scanning the database\u0026#34;, err) } singleRow := make([]string, len(cols)) for i, raw := range rawResult { singleRow[i] = string(raw) // from byte to string //fmt.Printf(\u0026#34;%v -\u0026gt; %v \\n\u0026#34;, i, singleRow) } allRows = append(allRows, singleRow) } fmt.Printf(\u0026#34;%v\\n\u0026#34;, allRows) Error: Error scanning row: sql: expected 1 destination arguments in Scan, not 3 Überprüfen, ob du in deinem SELECT-Statemnt wirklich 3 Spalten angefragt hast.\nSQL Compiler There is a library that compiles sql into type-safe code:\nhttps://github.com/sqlc-dev/sqlc Why this, there wouldn\u0026rsquo;t be the need to care about structs in go and about the sql-queries. I just would write sql and use the queries in go as functions!! Error Handling HTTP Maybe a nice read for a train drive:\nhttps://blog.questionable.services/article/http-handler-error-handling-revisited/ Commandline Arguments If you need something quick, without a variable info, just use this snippet:\nif len(os.Args) \u0026gt; 1{ for _ , s := range os.Args[1:]{ // index 0 is the name of the program, so slice it away switch s { case \u0026#34;--exporter\u0026#34;: db.Export() default: fmt.Printf(\u0026#34;Argument unknown: %s \\n\u0026#34;, s) os.Exit(0) } } } For more complex stuff, use the flag-package.\nWindows stuff If you think about call the powershell from golang like this:\ncmd := exec.Command(\u0026#34;powershell\u0026#34;, \u0026#34;-nologo\u0026#34;, \u0026#34;-noprofile\u0026#34;) There is also a windows-package to make syscalls: https://pkg.go.dev/golang.org/x/sys/windows\nContext The context-package is used to manage cancellation-signals, deadline and request-scoped values.\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { // Create a parent context parent := context.Background() // Create a child context with a deadline set to 100 ms ctx, cancel := context.WithDeadline(parent, time.Now().Add(100*time.Millisecond)) defer cancel() // Make sure to call cancel to release resources select { case \u0026lt;-time.After(200 * time.Millisecond): fmt.Println(\u0026#34;Operation completed\u0026#34;) // this won\u0026#39;t be reached case \u0026lt;-ctx.Done(): fmt.Println(\u0026#34;Operation canceled due to deadline\u0026#34;) // this will be reached } } Go-Routines Goroutines make concurrency possible. That means, running two seperate function seperatly without dependency between them. Different goroutines communicate via channels.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func count(name string) { for i := 1; i \u0026lt;= 5; i++ { fmt.Println(name, \u0026#34;:\u0026#34;, i) time.Sleep(100 * time.Millisecond) } } func main() { go count(\u0026#34;goroutine\u0026#34;) count(\u0026#34;main function\u0026#34;) time.Sleep(1 * time.Second) } Channels They allow safe data exchange and data synchronization between goroutines without shared memory access.\ngorilla/mux https://github.com/gorilla/mux Walk-Function If you want to get all GET-routes for building a navbar, you can use the Walk funktion.\ntype NavItem struct { Name string Path string } var nav []NavItem func IndexRoute(router *mux.Router){ router.Walk(func(route *mux.Route, router *mux.Router, ancestors []*mux.Route) error { path, _ := route.GetPathTemplate() method, _ := route.GetMethods() if len(method) \u0026gt; 0 \u0026amp;\u0026amp; method[0] == \u0026#34;GET\u0026#34;{ entry := NavItem{ Name: path, Path: path, } nav = append(nav, entry) } return nil }) } Code Analysis To see flaws in your code-base, you can use staticcheck ./...(external tool) or go vet ./...(part of the go toolchain).\nGUI frameworks To develop for the desktop, you\u0026rsquo;ll need some framework:\nhttps://wails.io/ ",
    "categories": ["coding"]
  },{
    "title": "Goose",
    "url": "https://hmaier-dev.github.io/wiki/goose/",
    "content": "Ist ein gutes Tool für Datenbank-Migrationen. Damit ist möglich inkrementell sql-Files einzuspielen. Verschiedenen Migrationen bauen also aufeinander auf. Mit Goose bildet man also die Evolution seiner Datenbank ab. Es ist möglich mit up und down zwischen den verschiedenen Evolutionsstufen zu switchen.\nNormaler Use-Case export DB_URL=postgres://postgres:password@172.17.0.3:5432/cmdb goose -allow-missing -dir ./migrations postgres $DB_URL up ## Wie sieht es in ./migrations aus? ## z.b. so: # . # ├── 00001_audit_log.sql # ├── 00002_cmdb.sql # ├── 00003_cables.sql # ├── 00004_domains.sql # ├── 00005_office.sql # ├── 20230119114311_cmdb_add_mac_addresses.sql # ├── 20230119160151_add_all_ips_view.sql # ├── 20230202173045_add_comments.sql # ├── 20230208194650_create_table_registered_domains.sql # ├── 20230316165343_cmdb_v2_add_mac_addresses.sql # ├── 20230320150211_cables_add_unique_constraints.sql # ├── 20230321100754_audit_table.sql # ├── 20230324171716_add_cables_references.sql # ├── 20230327134036_add_vm_spec_checks.sql # ├── 20230404161325_audit_search_path.sql # ├── 20230511123022_cables_v1_view.sql # ├── 20230523131012_add_shared_ip_type.sql # ├── 20230920143845_add_datacenter_ntt_ber1.sql # ├── 20240207104924_extract_location_functions.sql # ├── 20240207144735_create_table_cloud_machines.sql # ├── 20240207154335_cloud_is_label.sql # └── 20240318172042_add_cloud_contract_columns.sql Migration schreiben Dies ist eine Evolutionsstufe. Es wird definiert wie man, die Stufe erreicht (+goose Up) und wie man die Änderungen wieder rückgängig (+goose Down) macht.\n-- +goose Up -- +goose StatementBegin ALTER TABLE cmdb DROP CONSTRAINT status_format; ALTER TABLE cmdb ADD CONSTRAINT status_format CHECK (((status)::text ~* \u0026#39;^(online:.*|online:.*/.*|offline|security|ignore)$\u0026#39;::text)); -- +goose StatementEnd -- +goose Down -- +goose StatementBegin ALTER TABLE cmdb DROP CONSTRAINT status_format; ALTER TABLE cmdb ADD CONSTRAINT status_format CHECK (((status)::text ~* \u0026#39;^(online|online:.*|online:.*/.*|offline|security|ignore)$\u0026#39;::text)); -- +goose StatementEnd ",
    "categories": ["databases"]
  },{
    "title": "Helix",
    "url": "https://hmaier-dev.github.io/wiki/helix/",
    "content": "Helix is a modal text-editor. It is written in Rust (very important).\n",
    "categories": ["editors"]
  },{
    "title": "htmx",
    "url": "https://hmaier-dev.github.io/wiki/htmx/",
    "content": "HTMX is a javascript framework which should free the user from writing javascript. Find out how on the offical website: https://htmx.org/\nThis is the easiest way to use htmx: https://htmx.org/docs/#download-a-copy\nBasic POST-Request This is how you basically send an empty POST-request to the HTTP-Endpoint /disabled. Regarding golang, the htmx.min.js doesn't even have to be embedded into the binary.\n\u0026lt;head\u0026gt; \u0026lt;script src=\u0026#34;/htmx.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form hx-post=\u0026#34;/disable\u0026#34; \u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34; title=\u0026#34;Löscht /var/lib/automaintainer/enabled\u0026#34;\u0026gt; Deaktivieren \u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; Errorhandling Leider gibt es keine Magie um Errors mit htmx zu behandeln. Allerdings gibt es htmx-Event mit dem man arbeiten kann.\ndocument.body.addEventListener(\u0026#39;htmx:responseError\u0026#39;, function (evt) { document.querySelector(\u0026#39;body\u0026#39;).innerHTML = \u0026#39;\u0026#39;; document.querySelector(\u0026#39;body\u0026#39;).innerHTML = evt.detail.xhr.responseText; console.log(evt.detail.xhr); console.log(evt.detail.elt); console.log(evt.detail.target); console.log(evt.detail.requestConfig); }); Bei jeglichem Error wird auf dem Server generiertes HTML in den Body gepackt.\nTroubleshooting Die Logs ans die Konsole klemmen\nhtmx.logger = function(elt, event, data) { if(console) { console.log(\u0026#34;INFO:\u0026#34;, event, elt, data); } } ",
    "categories": ["Web-Development"]
  },{
    "title": "HTTP",
    "url": "https://hmaier-dev.github.io/wiki/http/",
    "content": "cURL Useful website to transform HTTP-request for different tools.\nhttps://curlconverter.com/ ",
    "categories": null
  },{
    "title": "Hugo",
    "url": "https://hmaier-dev.github.io/wiki/hugo/",
    "content": "Is a generator for static html.\nDevelop locally with Hugo If you already have the needed directory structure and you\u0026rsquo;d want to know how the website will look, just use\nhugo server and hugo will provide a local webserver for you. To open connections from your phone or another client in the local network use --bind.\nhugo server --bind 0.0.0.0 --baseURL http://\u0026lt;ip-of-you-device\u0026gt;:1313/wiki You can use --baseURL to overwrite the baseURL, so that you don\u0026rsquo;t have to change the hugo.toml. When developing locally you need to do either, because otherwise the css won\u0026rsquo;t load and links won\u0026rsquo;t direct correctly.\nConfig-file Hugo needs config-file, which default is hugo.toml.\nbaseURL = \u0026#34;https://hmaier-dev.github.io/wiki/\u0026#34; languageCode = \u0026#34;de-us\u0026#34; title = \u0026#34;Wiki\u0026#34; Configuration You will need several things for Hugo.\na ./content-directory with your knowlegde written in markdown (.md) some layout files under ./layouts/_default, so Hugo knows how to structure the site and a config file, which can be toml, json or something else Default directory structure looks like this\n├── content │ ├── _index.md │ └── some-page.md ├── hugo.toml ├── layouts │ ├── _default │ │ ├── baseof.html │ │ ├── index.html │ │ └── single.html │ └── partials │ ├── footer.html │ ├── header.html │ └── head.html └── static └── css Layouts There is a lookup-routine over which Hugo iterates. If it finds no Theme or other layouts, it will use the files in ./layouts/_default/. For example, these files could look like this.\nbaseof.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;{{ or site.Language.LanguageCode }}\u0026#34; dir=\u0026#34;{{ or site.Language.LanguageDirection `ltr` }}\u0026#34;\u0026gt; \u0026lt;body\u0026gt; \u0026lt;main\u0026gt; {{ block \u0026#34;main\u0026#34; . }}{{ end }} \u0026lt;/main\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; index.html: uses _index.md to generate the landing page (the underscores is mandatory) {{ define \u0026#34;main\u0026#34; }} {{.Content}} {{ end }} single.html: defines how a normal page (like some-page.md) would look {{ define \u0026#34;main\u0026#34; }} {{.Content}} {{ end }} In this example, there is no logic at all. Therefore your markdown gets converted in the most basic way.\nTemplating System If you have worked with the Golang-modules html/template or text/template, this should look familiar to you. Indeed you can use native Golang-functions, like printf or date. Also there is Metadata like .RelPermalink or .Title which is provided by Hugo. Use both docs for problem solving:\nhttps://gohugo.io/quick-reference/ https://pkg.go.dev/text/template For more examples, just look at:\nhttps://themes.gohugo.io/ Adding a variable to the REPLACEMENT when using replaceRE At first I glance it tried to manually insert the variable $Link (which is .RelPermalink) into the REPLACEMENT.\n{{ with .Content }} {{ $Link := .RelPermalink }} {{ . | replaceRE \u0026#34;(\u0026lt;h[1-9] id=\\\u0026#34;([^\\\u0026#34;]+)\\\u0026#34;.+)(\u0026lt;/h[1-9]+\u0026gt;)\u0026#34; `${1}\u0026lt;a href=\u0026#34;$Link#${2}\u0026#34; class=\u0026#34;hanchor\u0026#34; ariaLabel=\u0026#34;Anchor\u0026#34;\u0026gt;#\u0026lt;/a\u0026gt; ${3}` | safeHTML }} {{ end }} Doing it this way, the variable just won\u0026rsquo;t get display. Turns out I can use printf to alter the string before replaceRE does it jobs.\n{{ with .Content }} {{ $Link := $.RelPermalink }} {{ . | replaceRE \u0026#34;(\u0026lt;h[1-9] id=\\\u0026#34;([^\\\u0026#34;]+)\\\u0026#34;.+)(\u0026lt;/h[1-9]+\u0026gt;)\u0026#34; (printf `${1}\u0026lt;a href=\u0026#34;%s#${2}\u0026#34; class=\u0026#34;hanchor\u0026#34; ariaLabel=\u0026#34;Anchor\u0026#34;\u0026gt;#\u0026lt;/a\u0026gt; ${3}` $Link) | safeHTML }} {{ end }} [!TIP] By the way: You can do Anchors also this way: https://gohugo.io/render-hooks/headings/#examples But beware, you cannot use .RelPermalink when doing this.\nMenus In Hugo navbars are called menus.\nOffical docs: https://gohugo.io/content-management/menus/ Helpful article: https://harrycresswell.com/writing/menus-in-hugo/ Nav with all regular pages Regular pages are the ones, that you added. With site.AllPages you would receive more. This snippet would be located in layouts/partials/nav.html.\n\u0026lt;nav\u0026gt; {{ range site.RegularPages }} \u0026lt;ul\u0026gt; \u0026lt;a href=\u0026#34;{{ .RelPermalink }}\u0026#34;\u0026gt;{{ .LinkTitle }}\u0026lt;/a\u0026gt; \u0026lt;/ul\u0026gt; {{ end }} \u0026lt;/nav\u0026gt; Shortcodes Shortcodes are functions for custom html. You can embbed them into your markdown content or into your layouts. If you have some arguments like a changing src= or a different id= can use a shortcode. Shortcodes cannot be used in layouts. Use them inside your markdown content.\nHere are some example, made by the hugo-team:\nhttps://github.com/gohugoio/hugo/tree/master/tpl/tplimpl/embedded/templates/shortcodes Docs: https://gohugo.io/templates/shortcode/#create-custom-shortcodes Syntax Highlighting Hugo uses Chroma for syntax highlighting. Here is the link to the docs: https://gohugo.io/content-management/syntax-highlighting/\nRessources When trying to access a ressource this way, you need to have a assets-directory containing css/main.css. It won\u0026rsquo;t work with a static-directory.\n{{ $css := resources.Get \u0026#34;css/main.css\u0026#34; }} TailwindCSS By resources.Get you can pass the content to css.TailwindCSS which outputs into public/css/\u0026lt;name\u0026gt;.css. This is elegant because of two reasons:\nhugo server triggers a rebuild of css when it detects changes. (for this you need a tailwindcss-binary in your path, e.g. /usr/bin/tailwindcss) You don\u0026rsquo;t need to tailwindcss -i ./assets/css/input.css -o ./assets/css/output.css and linking the stylesheets to output.css before you build hugo. {{ with resources.Get \u0026#34;css/base.css\u0026#34; }} {{ $opts := dict \u0026#34;minify\u0026#34; true }} {{ with . | css.TailwindCSS $opts }} {{ if hugo.IsDevelopment }} \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;{{ .RelPermalink }}\u0026#34;\u0026gt; {{ else }} {{ with . | fingerprint }} \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;{{ .RelPermalink }}\u0026#34; integrity=\u0026#34;{{ .Data.Integrity }}\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; {{ end }} {{ end }} {{ end }} {{ end }} If you wan\u0026rsquo;t to turn off/on Tailwind for your css, just remove/add the following from/to the top of your base.css.\n@import \u0026#34;tailwindcss\u0026#34;; Where does Hugo search for tailwindcss? If you use the binary (https://tailwindcss.com/blog/standalone-cli) instead of the npm package, you might come across the problem of hugo not finding it probably. The error might look like this:\nERROR TAILWINDCSS: failed to transform \u0026#34;/css/base.css\u0026#34; (text/css): Error: Failed to find \u0026#39;tailwindcss\u0026#39; in [ C:\\Users\\user\\repo ] at C:\\snapshot\\tailwindcss\\node_modules\\postcss-import\\lib\\resolve-id.js:35:13 at async LazyResult.runAsync (C:\\snapshot\\tailwindcss\\node_modules\\postcss\\lib\\lazy-result.js:261:11) at async build (C:\\snapshot\\tailwindcss\\lib\\cli\\build\\index.js:49:9) Built in 5708 ms This is because your tailwind-binary isn\u0026rsquo;t registered in the PATH of your system.\nWindows: Search for env in the searchbar, and add the location of tailwind to your user-variables. Linux: Add location to your $PATH in your .profile or .bashrc If you are interested in which order hugo searches for tailwind; here is the LoC regarding this behaviour: https://github.com/gohugoio/hugo/blob/master/common/hexec/exec.go#L185\nDocs: https://gohugo.io/functions/css/tailwindcss/ Custom Output Formats You can generate all kinds of different data-structures with hugo. This can be helpful when making the sites available for other programs (e.g. search-function).\nIf you want generate search.json, which will be available at /, you need two things.\nThe configuration for a custom outputFormat in your hugo.toml and a template for generating the content of search.json The following is the config, that needs to be added to ypur hugo.toml.\n[outputFormats] [outputFormats.Search] mediaType = \u0026#39;application/json\u0026#39; baseName = \u0026#39;search\u0026#39; isPlainText = true [outputs] home = [\u0026#39;HTML\u0026#39;,\u0026#39;Search\u0026#39;] Besides the custom format Search, home also needs the instruction to generate HTML. Otherwise just the custom format would be generated. That\u0026rsquo;s why both are declared.\noutputs.\u0026lt;kind\u0026gt; needs a corresponding template in layouts/_default. In this case, with your Search-Format, it would be home.search.json. Without the custom output format the templates name would be home.json.json, which would generate index.json at /.\nIn a way the custom output format is just a way to alter the name of the generated file.\nIn the home.search.json-template you can declare all your needed data.\n[ {{- $first := true -}} {{- range .Pages -}} {{- if not $first -}},{{- end -}} { \u0026#34;title\u0026#34;: {{ .Title | jsonify }}, \u0026#34;url\u0026#34;: {{ .Permalink | jsonify }}, \u0026#34;content\u0026#34;: {{ .Plain | jsonify }} } {{- $first = false -}} {{- end -}} ] Reason for the name-schema of home.json.json and home.search.json: https://gohugo.io/templates/output-formats/#template-lookup-order Themes I might check out https://github.com/nodejh/hugo-theme-mini Troubleshooting and errors ÄÖÜäöü won\u0026rsquo;t render correctly Adding the charset to the head.html helps.\n\u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026ldquo;I want to see the all properties of an object.\u0026rdquo; You will get what you want with: {{ debug.Dump . }}. The dot will print the context your in, but you can also change it to a variable.\n",
    "categories": ["Web-Development"]
  },{
    "title": "Kubernetes",
    "url": "https://hmaier-dev.github.io/wiki/kubernetes/",
    "content": "Um zu lernen, wie Kubernetes funktioniert gibt es folgendes Repo:\nhttps://github.com/hmaier-dev/kubernetes-lab Damit kann man lokal ein Kubernetes-Cluster mit virtuellen Maschinen ausetzen.\n",
    "categories": ["Container"]
  },{
    "title": "LaTex",
    "url": "https://hmaier-dev.github.io/wiki/latex/",
    "content": "How to pass variables to LaTex? If you have a markdown-document and you have e.g. $fontsize$ in you documentclass, you can pass the variable into the YAML-header of the markdown-document.\nThis is the LaTex:\n\\documentclass[ $fontsize$, $for(classoption)$ $classoption$$sep$, $endfor$ ]{scrlttr2} And the markdown will look like this:\n--- fontsize: 12pt classoption: enlargefirstpage,firstfoot=false --- The actual text starts here... ",
    "categories": ["linux"]
  },{
    "title": "Light Directory Access Protocol",
    "url": "https://hmaier-dev.github.io/wiki/ldap/",
    "content": "Unix Credentials testen ldapsearch -x -H ldap://ldap.forumsys.com:389 -D \u0026#34;forumsys\\username\u0026#34; -w \u0026#34;super-secret-passwort\u0026#34; -b \u0026#34;\u0026lt;BIND_DN\u0026gt;\u0026#34; ",
    "categories": null
  },{
    "title": "lua",
    "url": "https://hmaier-dev.github.io/wiki/lua/",
    "content": "The most important software from Brasil.\nPrinting tables to the console Found on https://stackoverflow.com/questions/9168058/how-to-dump-a-table-to-console\nfunction dump(o) if type(o) == \u0026#39;table\u0026#39; then local s = \u0026#39;{ \u0026#39; for k,v in pairs(o) do if type(k) ~= \u0026#39;number\u0026#39; then k = \u0026#39;\u0026#34;\u0026#39;..k..\u0026#39;\u0026#34;\u0026#39; end s = s .. \u0026#39;[\u0026#39;..k..\u0026#39;] = \u0026#39; .. dump(v) .. \u0026#39;,\u0026#39; end return s .. \u0026#39;} \u0026#39; else return tostring(o) end end #### ODER local inspect = require(\u0026#39;inspect\u0026#39;) # externe lib print(inspect(out)) ",
    "categories": ["coding","editors"]
  },{
    "title": "Microsoft Excel",
    "url": "https://hmaier-dev.github.io/wiki/excel/",
    "content": "I am truly sad to write this article. I arrived in Corporate hell.\nFAQ How to reset all filters: CTRL+SHIFT+L default paste without format https://support.microsoft.com/en-us/office/control-the-formatting-when-you-paste-text-20156a41-520e-48a6-8680-fb9ce15bf3d6\nVordefinierte Spalten als Drop-Down-Menü Um die Dateneinträge sauber zu halten, bietet es sich an für eine Spalte ein vordefiniertes Drop-Down-Menü zu verwenden. Dazu nimmt eine eine separate Tabelle und definiert dort die vorgegebenen Werte. Diese wählt man dann aus und wählt mit einem Rechtsklick den Punkt Namen definieren aus.\nIn der Haupttabelle wählt man dann mitm STRG+SPACE die gesamte Spalte aus. Unter Daten \u0026gt; Datentools findet man Datenüberprüfung. Dort kann man unter Einstellungen Zulassen: Liste auswählen. Als Quelle gibt man dann den definierten namen an, z.B.: =Status.\nMöchte man die Werte des Drop-Down-Menüs ändern, muss man in der separaten Tabelle erst den Wert hinzufügen und kann dann über den Namens-Manager den erfassten Bereich ändern. Den Namens-Manager findet man entweder über die Suche oder unter Formeln \u0026gt; definierte Namen \u0026gt; Namens-Manager.\n",
    "categories": null
  },{
    "title": "Microsoft Outlook",
    "url": "https://hmaier-dev.github.io/wiki/outlook/",
    "content": " STRG+K in der Adresszeile um Mailadresse zu vervollständigen ",
    "categories": null
  },{
    "title": "Neovide",
    "url": "https://hmaier-dev.github.io/wiki/neovide/",
    "content": "This is written in rust (important!) and can do pretty graphical things.\nFont When opening up Neovide at first, the font might be a little to big. You can change this in your init.lua by adjusting h12-part.\nif v.g.neovide then v.o.guifont = \u0026#34;CaskaydiaCove Nerd Font:h12\u0026#34; end The used font can be downloaded here: https://github.com/ryanoasis/nerd-fonts/releases/download/v3.2.1/CascadiaCode.zip\n",
    "categories": ["Windows","editors"]
  },{
    "title": "Neovim",
    "url": "https://hmaier-dev.github.io/wiki/neovim/",
    "content": "Is a fork from the original vim-project. Some key-features are:\nLSP-Integration Configuration with lua Vimscript essentials The most fundamental config without lua.\nfiletype plugin indent on set expandtab set tabstop=2 set softtabstop=2 set shiftwidth=2 \u0026#34; Indentation and re-selection vnoremap \u0026gt; \u0026gt;gv vnoremap \u0026lt; \u0026lt;gv Keybindings Cheat Sheet These just work with my setup, which is not public (right now).\n\u0026lt;space\u0026gt;e = vim.diagnostic.open_float gd = Go to definition K = Show docs for this symbol \u0026lt;space\u0026gt;ff = telescope.builtin.find_files \u0026lt;space\u0026gt;fg = telescope.builtin.live_grep \u0026lt;space\u0026gt;fb = telescope.builtin.buffers \u0026lt;space\u0026gt;of = telescope.builtin.oldfiles \u0026lt;S\u0026gt;v+ \u0026lt;space\u0026gt;/ = comment out line/block Syntax-Highlighting By default neovim has native syntax highlighting which cannot take it up with Treesitter. When Treesitter is setup, you can install treesitter-parsers with the following command.\n:TSInstall \u0026lt;tab\u0026gt; By pressing the autocompletion shows you a plethora of installable languages.\nWith the :InspectTree you can display the the AST (Abstract-Syntax-Tree) in a speperate window.\nTreesitter-Install Beforehand you need to have Treesitter setup by your package-manager (in this case lazy.nvim):\nreturn { { \u0026#34;nvim-treesitter/nvim-treesitter\u0026#34;, build = \u0026#34;:TSUpdate\u0026#34;, config = function() require(\u0026#34;nvim-treesitter.configs\u0026#34;).setup( { ensure_installed = { \u0026#34;lua\u0026#34;, \u0026#34;vim\u0026#34;, \u0026#34;go\u0026#34;, \u0026#34;python\u0026#34;, \u0026#34;bash\u0026#34; }, auto_install = true, highlight = { enable = true, }, ignore_install = { \u0026#34;ruby\u0026#34; }, }) end, }, } How to rename a variable? There are several cases where you would want to rename a variable. The place before the s is reserved for the scope, which is:\n'\u0026lt;,'\u0026gt; currently selected % entire file Go to the string of your choice and press *. All matched occurences will be highlighted. Then do\n:%s/ With C-r you can paste the highlighted string. At first it looks like this\n:%s/\u0026#34; After a /:\n:%s/\\\u0026lt;string\\\u0026gt; Continue with another / and your wanted string.\n:%s/\\\u0026lt;string\\\u0026gt;/mynewstring/ You can now specifiy, if you want to change globally with g (don't know what this means) and if you want confirmation with c.\n:%s/\\\u0026lt;string\\\u0026gt;/mynewstring/gc Renaming a variable with LSP If you have lsp configured, you can do it with vim.lsp.buf.rename:\n-- Source: https://github.com/neovim/nvim-lspconfig?tab=readme-ov-file#suggested-configuration -- Keymaps for LSP v.keymap.set(\u0026#34;n\u0026#34;, \u0026#34;\u0026lt;space\u0026gt;e\u0026#34;, v.diagnostic.open_float) v.api.nvim_create_autocmd(\u0026#34;LspAttach\u0026#34;, { group = v.api.nvim_create_augroup(\u0026#34;UserLspConfig\u0026#34;, {}), callback = function(ev) local opts = { buffer = ev.buf } v.keymap.set(\u0026#34;n\u0026#34;, \u0026#34;\u0026lt;space\u0026gt;rn\u0026#34;, v.lsp.buf.rename, opts) end, }) Renaming a variable in your entire project The native vim-way goes like that:\n:grep \u0026lt;string\u0026gt; `\u0026lt;location\u0026gt;` :grep h.maier `find . -type f` The seconds command would search all subdirectorys for h.maier. Depending on the size of your project, this could take a while. You can always abort the grep with C-c. After finishing the search, you can load the found occurences into a quickfix list by doing a :copen.\nIf you use Telescope for searching (which is way more ergonimic than the grep-method) you can use C-q to load the found-occurences into a quickfix list.\nFrom there on, :cdo is your friend. Replacing a variable-name goes like this:\n:cdo %s/h.maier/nobody/gc :cdo lets you iterate through the quickfix list and execute the given command for every entry.\nAdding characters to the END of every line of selected text select the block of text with SHIFT + V enter command mode with : (colon) at first it will look like this :\u0026#39;\u0026lt;,\u0026#39;\u0026gt; go into normal mode with norm and write your commands :\u0026#39;\u0026lt;,\u0026#39;\u0026gt;norm A \u0026lt;the-string-of-my-choice\u0026gt; Add at the end of every line :%norm A\u0026lt;stuff-that-you-want-to-add\u0026gt; Which means:\n% = for every line norm = type the following commands A* = append ' * ' to the end of current line How to enter the commandline history? Just press q: (not :q). Now you can browse through are executed commands and copy them.\nPlugins The plugin manager of my choice is lazy.nvim. Have a look at lazy.folke.io to get to know how its done.\nLua Ein angenehmes Tool um den ganzen Lua-Code nach nem Herumfuschen übersichtlicher zu machen ist stylua. Mehr zu Lua gibt es hier: lua\nNeovim in the Browser https://github.com/coder/code-server Troubleshooting Fehler nach Updates von Plugins In einer Vielzahl von Fällen treten Probleme nach Updates von Plugins auf. Lässt sich der Fehler nicht zur eigenen Konfiguration, sondern in den Quellcode des Plugin zurückverfolgen, ist es am einfachsten das Plugin einfach neu zu installieren.\nDies funktioniert unter Lazy.nvim in dem man das geklonte Repository unter ~/.local/share/nvim/lazy/\u0026lt;repo\u0026gt; löscht.\n",
    "categories": ["editors"]
  },{
    "title": "Nginx",
    "url": "https://hmaier-dev.github.io/wiki/nginx/",
    "content": "SSL Mit certbot lässt sich SSL relativ einfach ab-frühstücken.\nZertifikat zu Domain hinzufügen Sub-Domäne zu bestehenden Zertifikat hinzufügen Bevor man eine neue (Sub-)Domäne zum Zertifikat hinzufügt, muss der DNS-Eintrag schon live sein.\ncertbot --expand -d existing.com -d www.exisiting.com -d newdomain.com https://eff-certbot.readthedocs.io/en/latest/using.html#re-creating-and-updating-existing-certificates Alias Mit alias kann man Pfad bereitstellen, der nicht mit der location zusammenpasst. Fordert man mit der root-Direktive den Pfad /preview/workshops/index.html an, würde Nginx nach /var/www/html/static-html/preview/workshops/index.html suchen. Die angeforderte URI wird also appended. Bei der folgenden Directory-Struktur würde man aber nix finden:\nstatic-html ├── about-me │ └── index.html ├── css │ └── style.css ├── favicon.ico ├── index.html ├── index.xml └── workshops └── index.html Mit der alias-Direktive wird der /preview/-Teil nicht mit angefordert, man kommt also /var/www/html/static-html/preview/workshops/index.html heraus.\nFür mehr, hier ist eine gute Erklärung auf StackOverflow:\nhttps://stackoverflow.com/questions/10631933/nginx-static-file-serving-confusion-with-root-alias Status Codes A status code is more than a number.\nhttps://developer.mozilla.org/en-US/docs/Web/HTTP/Status https://en.wikipedia.org/wiki/List_of_HTTP_status_codes When troubleshooting use curl -I \u0026lt;url\u0026gt; to get unfiltered insights into the reponse.\n403 Wenn man einen 403 erhält, kann man sich ziemlich sein, dass etwas mit den Permissions nicht stimmt. Daher den Owner sowie die Permissions der ganzen Directory überprüfen:\nls -la /var/www/html/static-html sudo chmod -R 755 /var/www/html/static-html` sudo chown www-data:www-data /var/www/html/static-html` Configs Static HTML This config just serves static html under the path /preview.\nalias When you want an URI with a different path in the filesystem, e.g. /var/www/html/static-html/page1/index.html but not /var/www/html/static-html/preview/page1/index.html, then alias is your directive of choice.\nindex Tells Nginx for which files to look, when a directory is requested. In this case index directs a directory-request to index.html. Without it http://localhost/preview/site1 would not work and would need http://localhost/preview/site1/index.html. Technically, if you have try_files setup that it directs to index.html, you wouldn\u0026rsquo;t need it.\ntry_files Looks for the different cases defined. Note that this hinders a redirect!\n$uri just takes the URI as it is. http://localhost/preview/index.html would connect, but http://localhost/preview/ not. $uri/index.html append the index.html. As it is the second case, existent URI with or without index.html would get 200. If nothing fits the schema, do a 404 response. Because of $uri/index.html, http://localhost/preview (without a trailing slash) as well as http://localhost/preview/ (with a trailing slash) will work!\nserver { server_name localhost; location /preview { alias /var/www/html/static-html; index index.html; try_files $uri $uri/index.html =404; } error_page 404 /404.html; access_log /var/log/nginx/website_access.log; error_log /var/log/nginx/website_error.log; } Reverse-Proxy with Docker-Container server { server_name localhost; location / { proxy_pass http://localhost:8080; proxy_redirect off; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_read_timeout 900; } access_log /var/log/nginx/docker_access.log; error_log /var/log/nginx/docker_error.log; } Header proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; Set the protocol to http or https ",
    "categories": ["Web-Development"]
  },{
    "title": "oscdimg.exe",
    "url": "https://hmaier-dev.github.io/wiki/oscdimg/",
    "content": "install.wim in ISO verpacken Dafür benötigt man oscdimg.exe, welches im Windows Assessment and Deployment Kit enthalten ist. Herunterladen kann man die ADK über folgenden Link\nhttps://learn.microsoft.com/en-us/windows-hardware/get-started/adk-install Der Standard-Installationpfad von oscdimg.exe ist folgender:\n%ProgramFiles(x86)%\\Windows Kits\\10\\Assessment and Deployment Kit\\Deployment Tools\\amd64\\Oscdimg Außerdem benötigt man eine funktionierende Standard Windows ISO. Nun müssen folgende Schritte gegangen werden.\nPer 7zip die ISO entpacken und nach sources navigieren. C:\\Win10_22H2_German_x64v1\\sources Dort die alte install.wim gegen die neue tauschen. Die ISO neu bauen. Da Oscdimg by default nicht in den Umgebungvariablen ist, sucht man nach Umgebung für Bereitstellungs- und Imageerstellungstools und start das Programm dann mit administrativen Rechten. Der Pfad in den man geworfen wird ist folgender: C:\\Program Files (x86)\\Windows Kits\\10\\Assessment and Deployment Kit\\Deployment Tools. Dort kann man dann folgendes Kommando ausführen.\noscdimg -bC:\\Win10_22H2_German_x64v1\\boot\\etfsboot.com -u2 -h -m -lCUSTOM_WIN C:\\Win10_22H2_German_x64v1 C:\\CustomWindows.iso Die Infos dieses Absatzes hab ich aus diesem Artikel: https://www.windowspro.de/wolfgang-sommergut/bootfaehige-iso-fuer-windows-image-wim-erstellendocx\nTroubleshooting Error 5 Starte Umgebung für Bereitstellungs- und Imageerstellungstools mit administrativen Rechten.\n",
    "categories": null
  },{
    "title": "Outline",
    "url": "https://hmaier-dev.github.io/wiki/outline/",
    "content": "Install The recommended way to run Outline is through a docker-compose.yml. You can find the docu here:\nhttps://docs.getoutline.com/s/hosting/doc/docker-7pfeLP5a8t The docker-compose.yml uses a docker.env for its environment-variables. You can find in on their Github:\nhttps://github.com/outline/outline/blob/main/.env.sample (also linked in the docu) Some variables are important for a functioning setup:\n## Set postgres ssl to false, otherwise there will be an error when running yarn PGSSLMODE=disable ## If your using traefik or another loadBalancer, turn off redirection FORCE_HTTPS=false Outline utilizes a postgres-database. Before the first startit needs to get initalized:\n## Creation docker compose run --rm outline yarn db:create --env=production-ssl-disabled ## Migration docker compose run --rm outline yarn db:migrate --env=production-ssl-disabled Run both commands in order.\nWhen creating the database, this error can appear:\nSequelize CLI [Node: 20.19.1, CLI: 6.6.2, ORM: 6.37.3] Loaded configuration file \u0026#34;server/config/database.json\u0026#34;. Using environment \u0026#34;production-ssl-disabled\u0026#34;. ERROR: getaddrinfo ENOTFOUND postgres error Command failed with exit code 1. info Visit https://yarnpkg.com/en/docs/cli/run for documentation about this command. The outline container cannot find the postgres-container. To fix that explicitly create a network and put all services in it.\nnetworks: outline-net: name: outline-net driver: bridge services: outline: networks: - outline-net postgres: container_name: postgres-outline # fixed hostname networks: - outline-net Also make sure to give the containers fixed names, so the variable in docker.env are right.\n## docker.env DATABASE_URL=postgres://user:pass@postgres-outline:5432/outline Also disable the metrics by setting\nENABLE_UPDATES=false Authentik as provider for Open ID Connect Reference:\nhttps://docs.goauthentik.io/integrations/services/outline/ https://docs.getoutline.com/s/hosting/doc/oidc-8CPBm6uC0I ",
    "categories": null
  },{
    "title": "pdf",
    "url": "https://hmaier-dev.github.io/wiki/pdf/",
    "content": "Tools wkhtmltopdf Can be used to convert html to pdf. Can be used a single binary, run in a docker container. Is uses a rather old webkit engine, which means newer css syntax won\u0026rsquo;t get rendered. For example, I had problems when using tailwindcss.\nThere is also a Golang-Library which utilizes the binary to create pdfs:\nimport( wkhtml \u0026#34;github.com/SebastiaanKlippert/go-wkhtmltopdf\u0026#34; ) Gotenberg Can be used to convert html into pdf. Runs within a docker container and is accessable via an API. I don\u0026rsquo;t have much experience with it, but I looks promising.\nocrmypdf Can be used to apply Optical Character Recogntion (OCR) to pdfs. It is written in python uses tesseract in backend. Because of several dependancys I recommend to use the a docker image.\ndocker run --rm -i jbarlow83/ocrmypdf-alpine Doc on how to use this on commandline: https://ocrmypdf.readthedocs.io/en/stable/docker.html#using-the-docker-image-on-the-command-line\n",
    "categories": null
  },{
    "title": "pgTAP",
    "url": "https://hmaier-dev.github.io/wiki/pgtap/",
    "content": "Testing mit pgTAP https://pgtap.org/pg_prove.html Pass if insertion fails BEGIN; -- Test to check if the INSERT statement fails as expected SELECT plan(1); PREPARE status_insert AS INSERT INTO cmdb (name, beschreibung, status) VALUES (\u0026#39;foobar\u0026#39;, \u0026#39;barfoo\u0026#39;, \u0026#39;online\u0026#39;); -- Passes if code and message match the thrown error when \u0026#39;status_insert\u0026#39; is executed SELECT throws_ok( \u0026#39;status_insert\u0026#39;, \u0026#39;23514\u0026#39;, -- wanted error code https://www.postgresql.org/docs/current/errcodes-appendix.html \u0026#39;new row for relation \u0026#34;cmdb\u0026#34; violates check constraint \u0026#34;status_format\u0026#34;\u0026#39;); -- wanted shown message SELECT * FROM finish(); ROLLBACK; ",
    "categories": ["databases"]
  },{
    "title": "PhoenixPE",
    "url": "https://hmaier-dev.github.io/wiki/phoenixpe/",
    "content": "A nice tool which helped me dozens of times:\nhttps://github.com/PhoenixPE/PhoenixPE https://www.heise.de/ratgeber/c-t-Notfall-Windows-2024-9549286.html ",
    "categories": ["Windows","System-Rescue"]
  },{
    "title": "Pihole",
    "url": "https://hmaier-dev.github.io/wiki/pihole/",
    "content": "Local DNS Records Unter System \u0026gt; Settings \u0026gt; Local DNS Records kann man lokale DNS Records pflegen. Es lassen sich sowohl A-Records als auch CNAME Records pflegen.\nHat man das Pihole am Router als DNS-Server eingetragen, kann es trotz korrekter Konfiguration sein, dass der Router DNS-Antworten, die auf IP-Adressen im eigenen Netzwerk verweisen, blockiert. Das kann sein, da auf dem Router der DNS-Rebind-Schutz aktiviert ist. Diesen zu deaktivieren ist in den meisten Fällen keine gute Idee. Allerdings kann man Ausnahmen für Domains angeben, die im eigenen Netzwerk verfügbar sind.\nDie Einstellung findet man unter Netzwerk \u0026gt; Netzwerkeinstellungen \u0026gt; DNS-Rebind-Schutz.\n",
    "categories": null
  },{
    "title": "Postgres",
    "url": "https://hmaier-dev.github.io/wiki/postgres/",
    "content": "Nützliche Kommandos Get all databases: \\l Connect to or better, use a database: \\c \u0026lt;db_name\u0026gt; Connect to db from shell: psql -h 172.17.0.2 -U postgres Import data into database: psql -h 172.17.0.3 -U postgres cmdb \u0026lt; ~/cmdb.sql Adminer in Docker starten, um Frontend für die Datenbank zu haben: docker run --name adminer --link cmdb -p 8080:8080 adminer Datenbank mit Docker aufsetzen: docker create --name cmdb -e POSTGRES_PASSWORD=password postgres:15 Postgres-URL: url=\u0026quot;postgres://postgres:password@172.17.0.3/cmdb\u0026quot; ",
    "categories": ["databases"]
  },{
    "title": "Powershell",
    "url": "https://hmaier-dev.github.io/wiki/powershell/",
    "content": "A collection of some powershell-snippets I found useful, can be found under:\nhttps://github.com/hmaier-dev/powershell-library/tree/main/src History You can get the history of your current powershell session with Get-History. To access older history, you can use the file stored under (Get-PSReadLineOption).HistorySavePath. In this file a maximum of (Get-PSReadLineOption).MaximumHistoryCount commands is stored.\nWith fzf you can access this list comfortably:\nfunction FuncFuzzySearchHistory(){ $cmd = $(Get-Content $((Get-PSReadLineOption).HistorySavePath) | fzf) $cmd Invoke-Expression $cmd } Prompt To change the behaviour of the powershell prompt before running the command, alter the prompt-function.\n## This sets the window-title with the last three dir of the path function prompt(){ $three = (Get-Location).Path -split \u0026#39;\\\\\u0026#39; | Select-Object -Last 3 $path = $three[0] + \u0026#34;\\\u0026#34; + $three[1] + \u0026#34;\\\u0026#34; + $three[2] $host.ui.RawUI.WindowTitle = $path \u0026#34;$(Get-Location)\u0026gt; \u0026#34; } Constructing an alias with arguments You can use the builtin-args variable for that.\nfunction DotFilesRepo(){ $base = \u0026#34;git.exe --git-dir=$env:USERPROFILE\\repos\\dotfiles\\ --work-tree=$env:USERPROFILE\u0026#34; $cmd = \u0026#34;$base $args\u0026#34; # The $args-variable is builtin and gets all arguments. Discoverd by accident. Invoke-Expression -Command $cmd } function DotFilesReposStatus(){ dfr status } Set-Alias -Name dfr -Value DotFilesRepo Set-Alias -Name dfrs -Value DotFilesReposStatus Aliases When constructing an alias with the corresponding function, keep in mind that powershell is not case-sensitive. That means, Set-Alias -Name wiki -Value Wiki would set alias that overwrites the function. My approach to this is to add the appropriate verb to the function name, e.g. Set-Alias -Name wiki -Value EnterWiki.\nParams If you want to use flags to activate a function, you can use a [switch].\nparam( [switch]$SetTaskScheduler = $False, ) Write-Host $SetTaskScheduler if ($SetTaskScheduler){ Write-Host \u0026#34;Setting the task\u0026#34; } Task Scheduler nice article: https://www.sharepointdiary.com/2022/06/create-scheduled-task-in-powershell.html Credentials Object If you want to safely pass username and password, you can create a Credentials object\n$username = \u0026#34;admin1234\u0026#34; $password = \u0026#34;mysupersecurepassword\u0026#34; [securestring]$secStringPassword = ConvertTo-SecureString $password -AsPlainText -Force [pscredential]$cred = New-Object System.Management.Automation.PSCredential ($username, $secStringPassword) Powershell Data File Instead of using json, yaml or another well-known config-file format for your script, you can go the native powershell way with psd1-file.\nA simple one-dimensional config (e.g. config.psd1) would look like this:\n@{ Username = \u0026#34;ftp-user\u0026#34; Password = \u0026#34;supersecretftppassword\u0026#34; Exclude = @(\u0026#34;PT*0730*.DAT\u0026#34;) ## Keep in mind that @() is for array and @{} is for hash table Paths = @( @{ Source = \u0026#39;L:\\FileServer\\Project1\u0026#39; Destination = \u0026#39;path/to/destination/on/server\u0026#39; }, @{ Source = \u0026#39;L:\\FileServer\\Project2\u0026#39; Destination = \u0026#39;path/to/destination/on/server\u0026#39; } ) } In your script you would import the config-file and access the variable like properties:\n$config = Import-PowershellDataFile -Path \u0026#34;.\\config.psd1\u0026#34; $config.Username $config.Password $config.Exclude Prettify Script For reformatting your scripts, you can use the following project: https://github.com/DTW-DanWard/PowerShell-Beautifier\nRun it as following: Edit-DTWBeautifyScript .\\export.ps1 to update the code.\nIt is available on scoop via scoop install main/powershell-beautifier.\nLDAP Query When working with powershell, you most certainly are living in a Windows Domain. With this premise you obviously won\u0026rsquo;t get along without doing some searching in the Active Directoy. With the following powershell-function you can make ldap-queries by using your current Kerberos Authentification. That means:\nLogon with your domain-user. Execute the script. Get data without inputting user+password. function GetUser(){ param ( [string]$username ) # Get the current domain name in DN format $domain = [System.DirectoryServices.ActiveDirectory.Domain]::GetCurrentDomain() $domainDN = ($domain.Name -split \u0026#34;\\.\u0026#34;) -join \u0026#34;,DC=\u0026#34; $domainDN = \u0026#34;DC=$domainDN\u0026#34; # Edit this to your needs $userPaths = @( \u0026#34;OU=Mitarbeiter,OU=IT,OU=Users\u0026#34;, ) foreach ($path in $userPaths) { $full = \u0026#34;LDAP://$path,$domainDN\u0026#34; $searcher = New-Object DirectoryServices.DirectorySearcher $searcher.SearchRoot = New-Object DirectoryServices.DirectoryEntry($full) $searcher.Filter = \u0026#34;(\u0026amp;(objectClass=user)(sAMAccountName=*$username*))\u0026#34; $searcher.PageSize = 1000 $searcher.FindAll() | ? { $user = $_.GetDirectoryEntry() # If you want to know all properties of an entry # you can use this: # $user.Properties.PropertyNames | ? { # Write-Host \u0026#34;$_ : $($user.Properties[$_])\u0026#34; # } $out = @\u0026#34; sAMAccountName: $($user.samaccountname.Value) mail: $($user.mail) dn: $($user.distinguishedName.Value) ----------------------------------------- \u0026#34;@ Write-Host $out } } } CSV Export For exporting data into a csv, you can use custom powershell-objects and pipe it to the Export-Csv function.\n$results foreach ($user in $allUsers) { $userObj = [PSCustomObject]@{ sAMAccountName = $user.sAMAccountName.value name = $user.name.value mail = $user.mail.value dn = $user.distinguishedName.value } $results += $userObj } } # Export the results to a CSV file $results | Export-Csv -Path \u0026#34;UserData.csv\u0026#34; -NoTypeInformation Delete UserProfiles via Wmi If you don\u0026rsquo;t have access via WinRM, you can use WMI (Windows Management Instrumentation) as an Alternative.\nRun this as Domain Administrator.\n## Show all profiles Get-WmiObject -Computername special_hostname -Class Win32_userprofile ## Show profile Get-WmiObject -Computername special_hostname -Class Win32_userprofile | Where { $_.LocalPath -like \u0026#34;*domainusername*\u0026#34; } ## Delete the profile Get-WmiObject -Computername special_hostname -Class Win32_userprofile | Where { $_.LocalPath -like \u0026#34;*domainusername*\u0026#34; } | Foreach { $_.Delete() } You will notice that your user is still present in the LogonUI. Clear out the keys with your username in this Registry-Path:\nmy-remote-machine\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Authentication\\LogonUI Register-WmiEvent Wmi (Windows Management Instrumentation) bietet unter Windows ein Schnittstelle um Informationen über den Zustand des Systems zu erhalten. Mit Powershell kann Register-WmiEvent nutzen, um auf das Eintreten eines Zustands zu reagieren. Zum Abhören eines Zustands muss man per WQL eine passende Query bauen.\nMS Docs: https://learn.microsoft.com/en-us/windows/win32/wmisdk/wql-sql-for-wmi WMI Code Creator: https://www.microsoft.com/en-us/download/details.aspx?id=8572 Tips and Tricks Get all line of go Get-ChildItem -Recurse -Include \u0026#39;*.go\u0026#39; | Get-Content | Measure-Object -Line ",
    "categories": ["Windows"]
  },{
    "title": "Python",
    "url": "https://hmaier-dev.github.io/wiki/python/",
    "content": "Is a nice scripting language which enables you to easily build everything, with the trade-off of it being slow.\nVirtual Environments Create a virtual environment in your current directory:\npython -m venv . You can install all kinds of packages with different version, without cluttering your host-system.\nLanguage Server Protocol For Python coding in neovim I recommend basedpyright. It was the easiest to run.\nUsually you would need npm to run pyright, but with basedpyright everything is compiled into on binaries you can execute. Here is their Github: https://github.com/DetachHead/basedpyright and it is available over :Mason.\nThe basic LSP configuration looks like this:\nrequire(\u0026#34;lspconfig\u0026#34;).basedpyright.setup({}) I want to see the traceback import traceback import sys try: do_stuff() except Exception: print(traceback.format_exc()) # or print(sys.exc_info()[2]) I want to have structs like in Go For this you can use dataclasses. These convert a class by annotation into a dataclass.\nfrom dataclasses import dataclass # Define a dataclass to hold the URIs and their expected status codes @dataclass class URI: uri: str want: int test = URI(uri=\u0026#34;https://www.nonexistentwebsite.com\u0026#34;, want=404), print(test.uri) print(test.want) Packaging a project https://packaging.python.org/en/latest/tutorials/packaging-projects/ Magic Packet A magic packet is a frame which is send as broadcast into the network, meant to start-up a computer which has Wake-On-LAN activated. In most cases the WOL-option can be found in the BIOS. The following script shows a function which takes any format of MAC-Address and broadcasts it to the network.\n#!/usr/bin/env python3 import socket import struct def wake_on_lan(mac_address): # Remove any separators from the MAC address and convert to bytes mac_bytes = bytes.fromhex(mac_address.replace(\u0026#39;:\u0026#39;, \u0026#39;\u0026#39;).replace(\u0026#39;-\u0026#39;, \u0026#39;\u0026#39;)) # Create the magic packet payload payload = b\u0026#39;\\xff\u0026#39; * 6 + mac_bytes * 16 # Set up the UDP socket sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) sock.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1) # Send the magic packet to the broadcast address on port 9 sock.sendto(payload, (\u0026#39;\u0026lt;broadcast\u0026gt;\u0026#39;, 9)) sock.close() mac_address = \u0026#39;F2:1F:AF:30:9F:10\u0026#39; # Replace with the target MAC address wake_on_lan(mac_address) LDAP Query This examples uses the current Kerberos ticket to auth to the ldap server. In most cases this will just work in Windows.\n# pip install -r requirements.txt # ldap3==2.9.1 # pyasn1==0.6.1 # winkerberos==0.12.2 import winkerberos as k from ldap3 import Server, Connection, SASL, GSSAPI, SUBTREE from dataclasses import dataclass from typing import Any, List # Use current users kerberos ticket. # See all active tickets with `klist`. def auth_kerberos(service_principal): print(f\u0026#34;\\nAttempting Kerberos authentication for SPN: {service_principal}\u0026#34;) try: status, ctx = k.authGSSClientInit(service_principal) if status != k.AUTH_GSS_COMPLETE and status != k.AUTH_GSS_CONTINUE: return False, f\u0026#34;Failed to initialize GSSAPI context: {status}\u0026#34; client_token = \u0026#34;\u0026#34; while status == k.AUTH_GSS_CONTINUE: print(\u0026#34;Current GSSAPI status: AUTH_GSS_CONTINUE\u0026#34;) status = k.authGSSClientStep(ctx, client_token) response_token = k.authGSSClientResponse(ctx) if response_token is None: if status == k.AUTH_GSS_COMPLETE: print(\u0026#34;GSSAPI authentication complete, no more client response needed.\u0026#34;) break else: return False, \u0026#34;GSSAPI step produced no response token.\u0026#34; print(\u0026#34;GSSAPI authentication complete.\u0026#34;) return True, \u0026#34;Authentication complete.\u0026#34; except k.GSSError as e: # This catches errors during the GSSAPI negotiation error_message = f\u0026#34;Kerberos GSSAPI Error: {e}\u0026#34; print(error_message) return False, error_message except Exception as e: # Catch other unexpected errors error_message = f\u0026#34;An unexpected error occurred: {e}\u0026#34; print(error_message) return False, error_message # End Kerberos Auth ATTRIBUTES = [ \u0026#39;distinguishedName\u0026#39;, \u0026#39;mail\u0026#39;, \u0026#39;mailNickname\u0026#39;] def browse(host, ous): print(f\u0026#34;Connecting to LDAP server: {host}\u0026#34;) server = Server(host, use_ssl=False) # Change use_ssl=True if needed # SASL GSSAPI = use current Kerberos ticket conn = Connection( server, authentication=SASL, sasl_mechanism=GSSAPI, auto_bind=True, read_only=True ) print(\u0026#34;LDAP bind successful.\u0026#34;) for ou in ous: cookie = b\u0026#39;\u0026#39; while True: conn.search( search_base=ou, search_filter=\u0026#39;(objectClass=user)\u0026#39;, search_scope=SUBTREE, attributes=ATTRIBUTES, paged_size=1000, paged_cookie=cookie ) read_page(conn) ## If Cookie is set, pull another page cookie = conn.result[\u0026#39;controls\u0026#39;][\u0026#39;1.2.840.113556.1.4.319\u0026#39;][\u0026#39;value\u0026#39;][\u0026#39;cookie\u0026#39;] if not cookie: break conn.unbind() ## There is a restriction for the amount of entries returned by a ldap-request def read_page(conn: Connection): for entry in conn.entries: for a in ATTRIBUTES: print(entry[a].values) # MAIN SERVICE_SPN = \u0026#34;\u0026#34; LDAP_HOST = \u0026#34;\u0026#34; OUs = [ \u0026#34;OU=IT,OU=Users,DC=company,DC=de\u0026#34;, ] success, result = auth_kerberos(SERVICE_SPN) print(success, result) browse(LDAP_HOST, OUs) Pandas Pandas sind nicht nur toll, sondern helfen auch zur Datenanalyse. Folgendes Beispiel: Ich habe zwei csv-Dateien in den ich jeweils einen identischen Key habe. Nun möchte ich die Einträgen zusammenführen, in denen in beiden Dateien der Key gleich ist. Mithilfe des Pakets pandas kann ich dafür einen Inner Join verwenden.\nimport pandas as pd bestellcenter_path = r\u0026#34;.\\bestellcenter-sim-numbers.csv\u0026#34; mdm_path = r\u0026#34;.\\mdm-data.csv\u0026#34; bc_df = pd.read_csv(bestellcenter_path, encoding=\u0026#34;cp1252\u0026#34;, sep=\u0026#34;;\u0026#34;, dtype={\u0026#34;SIM-Nummer\u0026#34;: str}) mdm_df = pd.read_csv(mdm_path, encoding=\u0026#34;cp1252\u0026#34;, sep=\u0026#34;,\u0026#34;, dtype={\u0026#34;SIM Karten Seriennummer\u0026#34;: str}) print(bc_df) print(mdm_df) mdm_df[\u0026#34;SIM Karten Seriennummer\u0026#34;] = ( mdm_df[\u0026#34;SIM Karten Seriennummer\u0026#34;].astype(str).str[6:] ) ## Bestellcenter key col1 = \u0026#34;SIM-Nummer\u0026#34; ## MDM Key col2 = \u0026#34;SIM Karten Seriennummer\u0026#34; # Ein Inner Join nimmt nur die Rows in denen der Key in beiden Datenframes gleich ist merged_df = pd.merge(bc_df, mdm_df, left_on=col1, right_on=col2, how=\u0026#34;inner\u0026#34;) # \u0026#39;~\u0026#39; is hier ein logischer NOT operator # Hole mir alle MDM Einträge die nicht im Bestellcenter sind not_matched_df = mdm_df[~mdm_df[col2].isin(bc_df[col1])] print(\u0026#34;SIM Karten, die im MDM und im Bestellcenter sind\u0026#34;) print(merged_df) print(\u0026#34;SIM Karten, die nicht im Bestellcenter gefunden wurden: \u0026#34;) print(not_matched_df) ",
    "categories": ["coding"]
  },{
    "title": "Raspberry_Pi",
    "url": "https://hmaier-dev.github.io/wiki/raspberry_pi/",
    "content": "Wlan to Ethernet-Bridge Hier ein Script welches, benötigte Programme herunterlädt, sowie ein systemd-unit baut, mit welchem sich die Bridge start lässt.\n#!/usr/bin/env bash set -e [ $EUID -ne 0 ] \u0026amp;\u0026amp; echo \u0026#34;run as root\u0026#34; \u0026gt;\u0026amp;2 \u0026amp;\u0026amp; exit 1 ########################################################## # You should not need to update anything below this line # ########################################################## # Because of the following two programs wifi and ethernet will share the same subnet # # parprouted - Proxy ARP IP bridging daemon # dhcp-helper - DHCP/BOOTP relay agent apt update \u0026amp;\u0026amp; apt install -y parprouted dhcp-helper systemctl stop dhcp-helper systemctl enable dhcp-helper # Enable ipv4 forwarding. sed -i\u0026#39;\u0026#39; s/#net.ipv4.ip_forward=1/net.ipv4.ip_forward=1/ /etc/sysctl.conf # Service configuration for standard WiFi connection. Connectivity will # be lost if the username and password are incorrect. systemctl restart wpa_supplicant.service # Enable IP forwarding for wlan0 if it\u0026#39;s not already enabled. grep \u0026#39;^option ip-forwarding 1$\u0026#39; /etc/dhcpcd.conf || printf \u0026#34;option ip-forwarding 1\\n\u0026#34; \u0026gt;\u0026gt; /etc/dhcpcd.conf # Disable dhcpcd control of eth0. grep \u0026#39;^denyinterfaces eth0$\u0026#39; /etc/dhcpcd.conf || printf \u0026#34;denyinterfaces eth0\\n\u0026#34; \u0026gt;\u0026gt; /etc/dhcpcd.conf # Configure dhcp-helper. cat \u0026gt; /etc/default/dhcp-helper \u0026lt;\u0026lt;EOF DHCPHELPER_OPTS=\u0026#34;-b wlan0\u0026#34; EOF # Enable avahi reflector if it\u0026#39;s not already enabled. sed -i\u0026#39;\u0026#39; \u0026#39;s/#enable-reflector=no/enable-reflector=yes/\u0026#39; /etc/avahi/avahi-daemon.conf grep \u0026#39;^enable-reflector=yes$\u0026#39; /etc/avahi/avahi-daemon.conf || { printf \u0026#34;something went wrong...\\n\\n\u0026#34; printf \u0026#34;Manually set \u0026#39;enable-reflector=yes in /etc/avahi/avahi-daemon.conf\u0026#39;\\n\u0026#34; } # I have to admit, I do not understand ARP and IP forwarding enough to explain # exactly what is happening here. I am building off the work of others. In short # this is a service to forward traffic from WiFi to Ethernet. cat \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; \u0026gt;/usr/lib/systemd/system/parprouted.service [Unit] Description=proxy arp routing service Documentation=https://raspberrypi.stackexchange.com/q/88954/79866 Requires=sys-subsystem-net-devices-wlan0.device dhcpcd.service After=sys-subsystem-net-devices-wlan0.device dhcpcd.service [Service] Type=forking # Restart until wlan0 gained carrier Restart=on-failure RestartSec=5 TimeoutStartSec=30 # clone the dhcp-allocated IP to eth0 so dhcp-helper will relay for the correct subnet ExecStartPre=/bin/bash -c \u0026#39;/sbin/ip addr add $(/sbin/ip -4 -br addr show wlan0 | /bin/grep -Po \u0026#34;\\\\d+\\\\.\\\\d+\\\\.\\\\d+\\\\.\\\\d+\u0026#34;)/32 dev eth0\u0026#39; ExecStartPre=/sbin/ip link set dev eth0 up ExecStartPre=/sbin/ip link set wlan0 promisc on ExecStart=-/usr/sbin/parprouted eth0 wlan0 ExecStopPost=/sbin/ip link set wlan0 promisc off ExecStopPost=/sbin/ip link set dev eth0 down ExecStopPost=/bin/bash -c \u0026#39;/sbin/ip addr del $(/sbin/ip -4 -br addr show wlan0 | /bin/grep -Po \u0026#34;\\\\d+\\\\.\\\\d+\\\\.\\\\d+\\\\.\\\\d+\u0026#34;)/32 dev eth0\u0026#39; [Install] WantedBy=wpa_supplicant.service EOF systemctl daemon-reload systemctl enable parprouted systemctl start parprouted dhcp-helper Normalerweise sollte das Script auch unter ~/.scripts/raspberrypi/bridge.sh liegen.\n",
    "categories": null
  },{
    "title": "Schach",
    "url": "https://hmaier-dev.github.io/wiki/schach/",
    "content": " \u0026times; Steinitzsche Ideen Welche positionellen Vorteile gibt es?\nEntwicklungsvorsprung im Eröffnungsstadium Größere Bewegungsfreiheit der Figuren (Mobility) Kontrolle im Zentrum Exponierte oder geschwächte Stellung des gegnerischen Königs Schwache Punkte im gegnerischen Lager Bessere Bauernstellung Bauernübergewicht am Damenflügel Kontrolle der Schwerfiguren über offene Linien, Beherrschung freier Diagonalen durch die Läufer Vorteil des Läuferpaares gegenüber Läufer und Springer oder zwei Springern ",
    "categories": null
  },{
    "title": "sqlite",
    "url": "https://hmaier-dev.github.io/wiki/sqlite/",
    "content": "Dump data mv sqlite.db sqlite.db.old sqlite3 sqlite.db.old .dump \u0026gt; backup.sql Insert dump Keep in mind that backup.sql contains a CREATE-statement. If you want to just keep the data, delete the concerning lines.\n# Linux sqlite3 sqlite-new.db \u0026lt; backup.sql # Windows Get-Content backup.sql | sqlite3.exe sqlite.db In-Memory database If you don\u0026rsquo;t want to create a file for the database, you can use the :memory: command. This way sqlite just creates a db in-memory, which gets delete when the process exists.\ndb, err := sql.Open(\u0026#34;sqlite\u0026#34;, \u0026#34;:memory:\u0026#34;) if err != nil { return err } ",
    "categories": ["databases"]
  },{
    "title": "ssh",
    "url": "https://hmaier-dev.github.io/wiki/ssh/",
    "content": "TL;DR Where to find the ssh access logs? Under /var/log/auth.log With sudo journalctl -t sshd -n 100 Basic config Host \u0026lt;name-you-want-to-type\u0026gt; HostName \u0026lt;ip\u0026gt; User \u0026lt;user\u0026gt; ",
    "categories": ["cli","linux"]
  },{
    "title": "SSL",
    "url": "https://hmaier-dev.github.io/wiki/ssl/",
    "content": "Check certificates openssl s_client -connect mysite.de:443 -showcerts Fullchain cat domain.cer intermediate.cer root.cer \u0026gt; fullchain.cer Test Certs https://www.ssllabs.com/\n",
    "categories": null
  },{
    "title": "sudo",
    "url": "https://hmaier-dev.github.io/wiki/sudo/",
    "content": "add user to sudoers-group sudo usermod -aG sudo \u0026lt;user\u0026gt; ",
    "categories": ["cli","linux"]
  },{
    "title": "sysprep.exe",
    "url": "https://hmaier-dev.github.io/wiki/sysprep/",
    "content": "Natives Windows-Programm zur Vorbereitung einer Installation, bevor man ein Image zieht. Normalerweise findet man das GUI-Programm sysprep.exe unter \\Windows\\System32\\Sysprep\\. Jeglich Logs und Fehlermeldungen die entstehen, findet man im Unterordner Panther\\.\nMöchte man sich ein Image ziehen und auf einem neuen Rechner installieren, empfehlen sich folgende Optionen:\nOOBE-Modus: Bei neuen Starten kommt man in die Out-Of-the-Box-Experience, wo man einen neuen User einrichten kann. (Es ist möglich diese mit einer Tastenkombination zu überspringen; bei W7 STRG+SHITF+F3) Verallgemeinern: Damit werden alle Treiber empfehlen. Bitlocker Bitlocker verhindert das Generalisieren via Sysprep. Entweder man schaltet Bitlocker über die Einstellungen aus (Einstellungen \u0026gt; Update \u0026amp; Sicherheit \u0026gt; Geräteveschlüsselung) oder man nutzt das cmd-Programm manage-bde mit manage-bde -off C:. Mit manage-bde -status kann man den Status aller Laufwerke einsehen.\nTroubleshooting Package failed waiting for remove operation sysprep not running dlls either the machine is in an invalid state Der Error sollte so ähnlich aussehen:\n[0x0f0073] SYSPRP RunExternalDlls:Not running DLLs; either the machine is in an invalid state or we couldn\u0026#39;t update the recorded state, dwRet= 1f [0x0f00ae] SYSPRP WinMain:Hit failure while processing sysprep cleanup external providers; hr = 0x8007001f Lösen kann man den Fehler, indem man in der Registry folgende Keys ändert.\nWindows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\\SYSTEM\\Setup\\Status\\SysprepStatus] \u0026#34;GeneralizationState\u0026#34;=dword:00000007 \u0026#34;CleanupState\u0026#34;=dword:00000002 ",
    "categories": null
  },{
    "title": "systemd",
    "url": "https://hmaier-dev.github.io/wiki/systemd/",
    "content": "Mostly found on modern distros. In use as an init-system to manage all services.\nmount units Um zu vermeiden in der /etc/fstab herumzupfuschen, kann man alternative (auto-)mount.units verwenden. Folgendes Schema ist dabei einzuhalten:\n/etc/systemd/system/path-to-mount.mount /etc/systemd/system/path-to-mount.automount ## path-to-mount.automount [Unit] Description=Automount networkshare [Automount] Where=/path/to/mount [Install] WantedBy=multi-user.target ## path-to-mount.mount [Unit] Description=some networkshare Wants=network-online.target After=network-online.target [Mount] What=//192.168.137.42 Where=/path/to/mount Type=cifs Options=credentials=/home/user/.smbcredentials,vers=2.1,noserverino,uid=1000,gid=1000 [Install] WantedBy=multi-user.target Source: Mount Network Drive with systemd on Startup\nsystemd-boot An einigen Rechner kann es vorkommen, dass bootctl install mit folgender Fehlermeldung fehlschlägt:\nUnable to write \u0026#39;LoaderSystemToken\u0026#39; EFI variable Dies sei laut systemd Github-Issue ein Hardware-Problem. Umgehen kann man dies in dem man die Flag --graceful anhängt.\nbootctl install --graceful Damit verhindert man das Abbrechen bei Fehlern.\njournalctl Show all messages from boot: journalctl -b Service Units Instead of tinkering around in the ~/.config/autostart directory, you also could write a small service unit.j When placing this in ~.config/systemd/user you can control it by adding the --user-flag to systemctl. That looks like the following: systemctl --user status syncthing.service.\n[Unit] Description=Syncthing service [Service] Type=simple ExecStart=/usr/bin/syncthing --no-browser ExecStop=killall syncthing [Install] WantedBy=multi-user.target ",
    "categories": ["linux"]
  },{
    "title": "tmux",
    "url": "https://hmaier-dev.github.io/wiki/tmux/",
    "content": "Is a terminal multiplexer which nullified my need for a tiling window manager.\nMove pane to new window CTRL+b; ! Resize pane in tty You need to remap the keys, because tty isn\u0026rsquo;t very advanced. https://superuser.com/questions/688807/how-to-resize-tmux-panes-inside-tty\nNew Session From within tmux you can use new -s in the tmux cli.\nCTRL+b; :; new -s mynewsession New base directory From within tmux you can use attach-session -c in the tmux cli.\nCTRL+b; :; attach-session -c ~/.config/nvim Rename tab Renames the current tab\nCTRL+b; , ",
    "categories": ["cli","linux"]
  },{
    "title": "Traefik",
    "url": "https://hmaier-dev.github.io/wiki/traefik/",
    "content": "General Configuration In Traefik the configuration is done in two different ways:\nstatic configuration dynamic configuration The static config can be though of as an startup config. It sets the connections to the different provides (file, docker, etc.) and sets the entrypoints (often just port 80 and 443). When something in this config changes, the traefik container needs to get restarted. Usally this should not happend often, because the values are mostly constant. You need to tell Traefik where it is when starting:\nservices: traefik: command: - \u0026#34;--configFile=/etc/traefik/traefik.yaml\u0026#34; volumes: - \u0026#34;./traefik.yml:/etc/traefik/traefik.yml:ro\u0026#34; The dynamic config is the way, how the magic can happens. Traefik uses different provides to get its routes, services and rules. The least magically way is to use the file-provider. You need to tell Traefik the dir to look for it:\nproviders: file: directory: \u0026#34;/rules\u0026#34; watch: true Make sure to mount it in the docker-compose.yml:\nservices: traefik: volumes: - \u0026#34;./rules:/rules\u0026#34; Dynamic Configuration Types In traefik there are different approaches to declare your configuration. Configuration is always received through a so named provider. Right now I have experience with two of the four categories of providers.\nLabel based (Docker) The label based configuration on might be the easiest. Just add traefik.-labels to the service in your compose file and you are good to go. A basic configuration for a nginx-webserver with http and https enabled, looks like this:\nservices: my-webserver: image: \u0026#34;nginx:bookworm\u0026#34; container_name: \u0026#34;static-wiki\u0026#34; volumes: - /opt/static-wiki/public/:/usr/share/nginx/html labels: traefik.enable: true # http traefik.http.routers.checklist.rule: PathPrefix(`/wiki`) traefik.http.routers.checklist.entrypoints: web # https traefik.http.routers.checklist-secure.tls: true traefik.http.routers.checklist-secure.rule: PathPrefix(`/wiki`) traefik.http.routers.checklist-secure.entrypoints: websecure networks: - traefik-net Traefik detects that port 80 of the container is open and therefore creates a service. The naming of the service can get a little ugly. Also, for me this kind of syntax isn\u0026rsquo;t very clear.\nFiles based The same configuration can be declared through the file based provider: an entry in the dynamic-config-file. It looks like this:\nhttp: routers: # http my-webserver: entrypoints: web rule: PathPrefix(`/my-unsafe-webserver`) service: nginx # https my-webserver-secure: entrypoints: websecure rule: PathPrefix(`/my-super-secured-webserver`) service: nginx tls: {} services: nginx: loadBalancer: servers: - url: \u0026#34;http://my-webserver:80\u0026#34; Because this is declared in the dynamic-config-file, you won\u0026rsquo;t need to restart the container to make it work.\nProject Example I like to go for the file-based dynamic configuration. Meaning, I create a separate directory called ./rules which I mount into the container. For every service I create a separate file.\n. ├── apps ## Services plus their config │ ├── authentik │ │ └── compose.yml │ └── outline │ └── compose.yml ├── compose.yml ## Traefik compose ├── LICENSE ├── README.md ├── rules ## Dynamic Config │ ├── authentik.yml │ └── outline.yml └── traefik.yml ## Static Config Certificates Self signed certs\nhttps://doc.traefik.io/traefik/expose/docker/#create-a-self-signed-certificate\nResources https://doc.traefik.io/traefik/user-guides/docker-compose/basic-example/ https://doc.traefik.io/traefik/getting-started/quick-start/ API The API is reachable over port 8080. These are the available endpoint over GET:\nhttps://doc.traefik.io/traefik/operations/api/#dashboard Templating When you want deploy a lot of services but you don\u0026rsquo;t want to type all of them out, you could use Go Templating.\nhttps://doc.traefik.io/traefik/providers/file/#go-templating Configuration Examples Webserver with HTTPS http: routers: website: entrypoints: - web - websecure rule: Host(`www.mysite.com`) || Host(`mysite.com`) service: website tls: {} services: website: loadBalancer: servers: - url: \u0026#34;http://website:8080\u0026#34; ~ ",
    "categories": null
  },{
    "title": "Vagrant",
    "url": "https://hmaier-dev.github.io/wiki/vagrant/",
    "content": "Vagrant ermöglicht die Erstellung und Verwaltung von virtuellen Maschinen.\nTL;DR vagrant init: erstellt in der derzeitigen Directory ein sogenanntes Vagrantfile vagrant status: zeigt den Status der sogenannten Boxes (VMs) in der derzeitigen Directory vagrant global-status: zeigt Status alles Boxes auf der Host-Maschine vagrant up: Startet alle definierten Maschinen vagrant up \u0026lt;name\u0026gt;: Startet mit \u0026lt;name\u0026gt; benannte Maschine vagrant destroy: Stoppt und verwirft alle Maschinen vagrant provision \u0026lt;name\u0026gt;: Wiederholung der Provision einer Machine. Bspw.: über Puppet, Ansible Wenn man etwas am Vagrantfile ändern, kann man seine Änderungen mit vagrant reload für alle Maschine anwenden. Virtualbox als Default-Provider Vagrant wählt zwischen Docker und VirtualBox als Backend/Provider für die VMs. Setzt man diese Umgebungsvariable (z.B. in ~/.profile) legt mn VirtualBox fest.\nexport VAGRANT_DEFAULT_PROVIDER=virtualbox Vagrantfile für Ubuntu-Maschine Vagrant.configure(\u0026#34;2\u0026#34;) do |config| config.vm.box = \u0026#34;bento/ubuntu-22.04\u0026#34; config.vm.network \u0026#34;private_network\u0026#34;, ip: \u0026#34;192.168.56.10\u0026#34; end ",
    "categories": ["Virtualization"]
  },{
    "title": "Wayland",
    "url": "https://hmaier-dev.github.io/wiki/wayland/",
    "content": "Everything about wayland can be read in\nhttps://wayland-book.com/ Application Brave-Browser To use the brave browser on wayland, you need to add some flags.\n## ~/.config/brave-flags.conf --enable-features=UseOzonePlatform --ozone-platform=wayland After this brave should start flawless. (Tested on Brave Browser 139.1.81.137)\nKeyboard Wayland uses xkb under the hood. There are several xkb programs (e.g. xkbcli) which can help you with problem solving.\nKeepassXC Usually build with Qt-5. Using Qt-5 it needs the env-variable QT_QPA_PLATFORM=wayland to start. Force it by setting it in the terminal:\nQT_QPA_PLATFORM=wayland keepassxc If you don\u0026rsquo;t know wether your programm was build with Qt-5, you can check the linked library with ldd\nldd $(which keepassxc) | grep Q ",
    "categories": null
  },{
    "title": "WebAssembly",
    "url": "https://hmaier-dev.github.io/wiki/webassembly/",
    "content": "Make things in the browser fast, vroom vroom.\nGolang When building WebAssembly in Go, just have to change the GOOS and GOARCH variable as following:\nGOOS=js GOARCH=wasm go build -o main.wasm Some parts of the code won\u0026rsquo;t be compatible with the GOOS=js. You can exclude them by making a comment a the top of the file:\n//go:build !js Now you can try to build again.\nRessources: https://go.dev/wiki/WebAssembly#getting-started ",
    "categories": ["Web-Development"]
  },{
    "title": "Windows",
    "url": "https://hmaier-dev.github.io/wiki/windows/",
    "content": "Appx-Packages Möchte man Appx-Packages installieren unterscheidet man zwischen zwei Arten von Kommando-Gruppen. Einerseits die Kommandos für *-AppxPackage und *-AppxProvisionedPackage.\nMit den AppxPackage-Kommando kann man im normalen User-Space AppX-Pakete hinzufügen. Diese sind damit auf dem momentan angemeldeten Profil verfügbar. Möchte man das alle Benutzer dieses Paket erhalten, kann man mit AppxProvisionedPackage arbeiten. Bei der Anmeldung wird damit für den jeweiligen Benutzer die App provisioniert.\nDabei ist wichtig zu beachten, dass man das -Online-Flag nutzt. Damit bearbeitet man die aktuell laufende Windows-Installation. Ohne das -Online-Flag kann man ein Windows-Image bearbeiten, muss dann aber den -Path mit angeben. In der Microsoft-Doku gibt es dafür zwei gute Beispiele:\nhttps://learn.microsoft.com/en-us/powershell/module/dism/add-appxprovisionedpackage?view=windowsserver2025-ps#examples Re-register Apps When some apps fail. try this.\nGet-AppXPackage -AllUsers | Foreach {Add-AppxPackage -DisableDevelopmentMode -Register \u0026#34;$($_.InstallLocation)\\AppXManifest.xml\u0026#34;} Desktop Anwendung in MSIX packen https://learn.microsoft.com/de-de/windows/msix/packaging-tool/tool-overview Drucker-Port/Anschlüsse löschen Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Print\\Monitors\\Standard TCP/IP Port\\Ports Drucker löschen Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Print\\Printers\\ Enable-PSRemoting als GPO Computer Cponfiguration \u0026gt; Administrative Templates \u0026gt; Windows Components \u0026gt; Windows Remote Management (RM) \u0026gt; WinRM Service \u0026gt; Allow remote server management through WinRM Force re-creation of Userprofile In manchen Fällen kann das Userprofil eines Benutzers beschädigt oder anders korrupiert sein. Um dies zu beheben, muss man in folgenden Registrypfad gehen und das betreffende Profil löschen:\nHKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\ProfileList\nhttps://superuser.com/questions/512484/how-do-i-force-windows-7-to-create-a-new-domain-profile-with-same-name-as-an-exi\nSound Settings Hier kommt man ins alte Sound-Menü mmsys.cpl.\nWindows 11 on unsupported Hardware Mit diesem Script hat es gut funktioniert: https://gist.github.com/asheroto/5087d2a38b311b0c92be2a4f23f92d3e\nDrucker Um die Druckerwarteschlange abzuhören, bzw. zu loggen, kann man folgendes Powershell-Skript nutzen:\n## Diese Attribute findet man unter: https://learn.microsoft.com/de-de/windows/win32/cimwin32prov/win32-printjob#syntax ## All Atributes of Win32_PrintJob # $job.TimeSubmitted # $job.Caption # $job.Description # $job.Document # $job.HostPrintQueue # $job.JobId # $job.JobStatus # $job.Name # $job.Notify # $job.Owner # $job.PagesPrinter # $job.PaperLength # $job.PaperSize # $job.PaperWidth # $job.TotalPages # $job.Color # $job.DataType # $job.DriverName $LogFile = \u0026#34;C:\\Users\\superSpecialUser\\Desktop\\PrintJobLog.txt\u0026#34; if (-not (Test-Path $LogFile)) { New-Item -Path $LogFile -ItemType File -Force | Out-Null } try { $create = \u0026#34;JobCreation\u0026#34; Register-WmiEvent -Query \u0026#34;SELECT * FROM __InstanceCreationEvent WITHIN 1 WHERE TargetInstance ISA \u0026#39;Win32_PrintJob\u0026#39;\u0026#34; -SourceIdentifier $create -Action { $job = $Event.SourceEventArgs.NewEvent.TargetInstance $action = \u0026#34;NEW JOB\u0026#34; $raw = $job.TimeSubmitted.Substring(0,14) $dt = [datetime]::ParseExact($raw, \u0026#34;yyyyMMddHHmmss\u0026#34;, $null) $time = $dt.ToString(\u0026#34;yyyy-MM-dd_HH-mm-ss\u0026#34;) $msg = \u0026#34;$($time) =\u0026gt; [$($action)] | $($job.Caption) $($job.HostPrintQueue) $($job.Owner) $($job.Document) ($($job.JobId))\u0026#34; Write-Host $msg $msg | Out-File \u0026#34;C:\\Users\\superSpecialUser\\Desktop\\PrintJobLog.txt\u0026#34; -Append } $remove = \u0026#34;JobRemoved\u0026#34; Register-WmiEvent -Query \u0026#34;SELECT * FROM __InstanceCreationEvent WITHIN 1 WHERE TargetInstance ISA \u0026#39;Win32_PrintJob\u0026#39;\u0026#34; -SourceIdentifier $remove -Action { $job = $Event.SourceEventArgs.NewEvent.TargetInstance $action = \u0026#34;JOB REMOVED\u0026#34; $raw = $job.TimeSubmitted.Substring(0,14) $dt = [datetime]::ParseExact($raw, \u0026#34;yyyyMMddHHmmss\u0026#34;, $null) $time = $dt.ToString(\u0026#34;yyyy-MM-dd_HH-mm-ss\u0026#34;) $msg = \u0026#34;$($time) =\u0026gt; [$($action)] | $($job.HostPrintQueue) $($job.Owner) $($job.Document) ($($job.JobId))\u0026#34; Write-Host $msg $msg | Out-File \u0026#34;C:\\Users\\superSpecialUser\\Desktop\\PrintJobLog.txt\u0026#34; -Append } Write-Host \u0026#34;Monitoring for new processes. Press Ctrl+C to stop.\u0026#34; # Use a loop to keep the script running and the session active. while ($true) { Start-Sleep -Seconds 5 } } finally { Write-Host \u0026#34;Unregister and remove: $create\u0026#34; Unregister-Event -SourceIdentifier $create Get-Job -Name $create | Remove-Job -Force Write-Host \u0026#34;Unregister and remove: $remove\u0026#34; Unregister-Event -SourceIdentifier $remove Get-Job -Name $remove | Remove-Job -Force } WMI Diese verschiedenen Objekte kann man mit WMI abhören:\nhttps://learn.microsoft.com/de-de/windows/win32/cimwin32prov/computer-system-hardware-classes Unter den verschiedenen Klassen findet man den jeweils die Attribute.\nInstallers On Windows there are several installers types, which enable the admin to rollout the software in different ways.\nNSIS https://nsis.sourceforge.io/Main_Page\nMSI Mit der Windows ADK erhält man hilfreiche Einblicke in MSI-Pakete:\nhttps://developer.microsoft.com/de-de/windows/downloads/windows-sdk/ ",
    "categories": null
  },{
    "title": "Windows_Terminal",
    "url": "https://hmaier-dev.github.io/wiki/windows_terminal/",
    "content": "Finally a usable terminal for windows with support for nerd-fonts and multiplexing (split-screen).\nTL;DR New Tab CTRL+TAB+T Cycle through the tabs CTRL+TAB (forwards) CTRL+SHIFT-TAB (backwards) Split Pane \u0026lt;SHIFT\u0026gt;-\u0026lt;ALT\u0026gt;-\u0026lt;-\u0026gt; horizontal \u0026lt;SHIFT\u0026gt;-\u0026lt;ALT\u0026gt;-\u0026lt;+\u0026gt; vertical Resize Pane ALT-SHIFT-Arrow_Keys Where to find more on tiling the panes? https://learn.microsoft.com/en-us/windows/terminal/panes Nerd-Fonts fürs Windows Terminal Link herunterladen:\nhttps://github.com/ryanoasis/nerd-fonts/releases/download/v3.2.1/CascadiaCode.zip Diesen Link findet man auch unter https://www.nerdfonts.com/font-downloads\nDen Ordner extrahieren und mit CTRL+a alle Dateien auswählen. Mit Rechtsklick kann man dann alle auf einmal installieren.\n",
    "categories": ["Windows"]
  },{
    "title": "winget",
    "url": "https://hmaier-dev.github.io/wiki/winget/",
    "content": "Scopes Möchte man eine App auf allen Benutzerprofilen installieren wählt man den --scope machine. Hat man keine administrativen Rechte benutzt man --scope user und das Programm wird nur im eigenen Profil installiert.\n",
    "categories": null
  },{
    "title": "Wireguard",
    "url": "https://hmaier-dev.github.io/wiki/wireguard/",
    "content": "Does VPN. The easy way.\nTL;DR wg show \u0026lt;interface\u0026gt;: wg-quick down \u0026lt;interface\u0026gt;: Wireguard ausschalten ip link delete \u0026lt;interface\u0026gt;: Wireguard-Interface löschen Wireguard Wie auch beim Tunneln mit anderen Protokollen, brauchen meine wg-Clients einen öffentlichen Ansprechpartner im Internet, den wg-Server.\nMit diesen Script kann ein Großteil der gängigen Linux-Distros in einen solchen wg-Server umwandeln.\nInstaller-Script für den Server: https://github.com/angrisnttan/wireguard-install Außerdem lassen sich nach erstmaliger Installation, weitere Clients erstellen. Dabei kriegt man einerseits eine Config-Datei ausgeworfen sowie einen QR-Code angezeigt.\nIch kann mir also theoretisch Clients vorgenerieren lassen und die später an die jeweiligen Leute verteilen (cool!).\nwg-quick Mit wg-quick kann man sich viel manuelle Konfiguration abnehmen lassen und den Tunnel aus schnelle Weise an-/ausschalten. Es werden root-Rechte benötigt. Auf dem Default-Weg sucht wg-quick nach der Konfiguration für ein Interface unter /etc/wirguard/\u0026lt;interface\u0026gt;.conf. Liegt die Config dort nicht mehr und der Tunnel ist aktiv, kann man sich die derzeitige Config über wg showconf \u0026lt;interface\u0026gt; ausgeben lassen und neu in dorthin schreiben lassen.\nwg showconf \u0026lt;interface\u0026gt; \u0026gt; /etc/wireguard/\u0026lt;interface\u0026gt;.conf Indicator für Gnome Mit dem Indicator kann ich über die Gnome-Oberfläche (siehe Extenstion-Repo) die Verbindung per Mausklick an und aus schalten.\nExtension für den Indicator: https://github.com/atareao/wireguard-indicator (lässt sich am besten über den gnome-shell-extension-manager installieren) Das Config-File welches man vom Server bekommt, muss wie das zu erstellende Interface heißen.\nmv my-laptop-wg0.conf wg0.conf Dann kann man es per nmcli hinzufügen.\nsudo nmcli connection import type wireguard file wg0.conf Im Indicator sollte jetzt die Verbindung wg0 angezeigt werden.\nTroubleshooting wg0-Interface wird nach jedem boot neu erstellt Wenn man Wireguard-Verbindungen vom NetworkManager verwalten lässt, schreibt dieser ein Konfiguration für das wg0-Interface. Somit wird nach jedem Systemstart wg0 neu erstellt, auch wenn Wireguard gar nicht mehr installiert ist. Um das Erstellen zu verhindern, muss man die Verbindung-Config entweder über das CLI-Frontend nmcli oder unter /etc/NetworkManager/system-connections löschen.\n",
    "categories": ["linux","networking"]
  },{
    "title": "Wordpress",
    "url": "https://hmaier-dev.github.io/wiki/wordpress/",
    "content": "Die folgende Anleitungen leiten im Theme Twenty Seventeen an.\nWie ändere ich das Header-Bild einer Seite? Im Admin-Dashboard auf Seiten \u0026gt; Alle Seiten gehen und die betreffende Seite Bearbeiten. Auf das blaue Plus auf der oberen linken Seite drücken, was dem Block-Inserter erscheinen lässt. Im Suchfeld oder manuell (Unterpunkt: Theme) nach Beitragsbild suchen und darauf klicken. Das aktuelle Beitragsbild/Header-Bild erscheint im Editor und lässt sich mit einem Klick auf die drei Punkte ändern. Möchte man es entfernen, muss man statt Löschen auf Zurücksetzen gehen. Wie ändere ich die Startseite? Im Admin-Dashboard auf Design \u0026gt; Customizer gehen. Unter Theme-Optionen und Inhalt im Startseiten-Abschnitt 1-5 kann man die verschiedene Seiten auswählen, die auf der Startseite angezeigt werden sollen. Wie ändere ich die URL einer Seite? Im Admin-Dashboard auf Seiten \u0026gt; Alle Seiten gehen. Mit der Maus über den Listeneintrag der Seiten fahren. QuickEdit auswählen. In dem Feld Titelform lässt sich der Name der Seite in der URL ändern. Errors Der Server kann das Bild nicht verarbeiten. Dies kann vorkommen, wenn der Server beschäftigt ist oder nicht genug Ressourcen hat, um die Aufgabe abzuschließen. Es könnte helfen, ein kleineres Bild hochzuladen. Die maximale Größe sollte 2560 Pixel nicht überschreiten. Wahrscheinlich ist das Bild im Format .jpeg oder .png vorhanden. Hier kann eine Konvertierung zu .webp helfen.\ncwebp -q 80 bild.jpg -o bild.webp Damit wird das Bild verkleinert und \u0026quot;sichtbarer\u0026quot; (?) für Suchmaschinen gemacht.\nRessourcen Basic Setup: https://ubuntu.com/tutorials/install-and-configure-wordpress#1-overview ",
    "categories": null
  },{
    "title": "yt-dlp",
    "url": "https://hmaier-dev.github.io/wiki/yt-dlp/",
    "content": "Download mp3 For downloading mp3, use the following flags:\nyt-dlp -x --audio-format mp3 \u0026lt;url\u0026gt; Make sure ffmpeg exists on the machine.\n",
    "categories": null
  },{
    "title": "zsh",
    "url": "https://hmaier-dev.github.io/wiki/zsh/",
    "content": "PROMPT This will display a basic prompt containing the username and the path.\nPROMPT=\u0026#39;%F{cyan}%n%f %F{yellow}%~%f %F{green}❯%f \u0026#39; ",
    "categories": ["Linux","cli"]
  }]
